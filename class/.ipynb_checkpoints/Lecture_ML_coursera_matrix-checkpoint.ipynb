{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector, Matrix, Tensor\n",
    "\n",
    "앞으로 다루게 될 변수, 연산은 전부다 vector, matrix 혹은 tensor의 형태를 띌 것이므로 잘 알아두어야 한다. \n",
    "\n",
    "데이터가 어떤 형태로 다루어지는지를 보도록 하자. \n",
    "\n",
    "### 1. Scalar to Tensor <br> \n",
    "\n",
    "**1) rank(차원)** \n",
    "\n",
    "tensor는 쉽게 말해서 n-차원 array(배열)이라고 생각하면 쉽다. 0차원 배열은 scalar, 1차원 배열은 vector이고 <br>\n",
    "2차원 배열은 matrix, 그 이상은 n-차원 tensor라고 보통 일컫는다. <br>\n",
    "그리고 각각에 rank가 존재하는데 차원과 같은 값이다. rank는 어떻게 표현하느냐에 따라서 달라지기도 하는데 vector의 <br>\n",
    "경우 1차원 tensor로 나타낼 수도 있고 2차원 tensor로도 나타낼 수 있다. <br>\n",
    "numpy를 다루다보면 이러한 특징이 매우 짜증나면서도 중요한 역할을 할 때가 있다. 더 자세한건 뒤에서 **broadcasting**을 설명하면서\n",
    "얘기하도록 하겠다. \n",
    "\n",
    "```python\n",
    ">>> tensor_1D = np.array([1,1])\n",
    ">>> tensor_2D = np.array([[1,1]])\n",
    ">>> print(tensor_1D)\n",
    ": (2,)\n",
    ">>> print(tensor_2D)\n",
    ": (1,2)\n",
    "```\n",
    "아래 그림에서 rank에 따른 scalar, vector, matrix ... 의 값들에 대해서 설명이 잘 되어있다. \n",
    "![rank](https://github.com/whikwon/studyroom/pictures/tensor_rank.png) <br>\n",
    "\n",
    "**2) shape** : \n",
    "\n",
    "tensor의 **형태?** 를 표현해주는 표현 방법이다. 아래 그림에 잘 나와있다.\n",
    "![shape](https://github.com/whikwon/studyroom/pictures/tensor_shape.png) <br>\n",
    "rank가 0인 scalar의 경우 값들의 입력 폭이 없으므로 Shape는 당연히 아무것도 없는 `[]`로 표현된다. <br>\n",
    "rank가 1인 vector의 경우는 한 방향으로 값이 입력될 수 있으니 Shape는 `[D0]`으로 표현된다. <br>\n",
    "matrix, n-D tensor도 마찬가지로 Shape에서 방향의 개수(차원) 만큼 입력될 수 있는 성분이 존재한다. <br>\n",
    "\n",
    "주로 데이터를 다룰 때 Coursera 강의에서는 `X`는 거의 `m x n` matrix 값이 주어지고 y는 `1 x n`의 matrix(*혹은 vector*)가 주어진다. <br> 이럴 때, 단순히 `weight`와 `X`와 dot product를 하는 예제라면 `X, Y`의 shape를 고려해서 `weight`의 shape를 유추할 수 있겠다. \n",
    "\n",
    "이런 식으로 tensor를 다룰 때에는 scalar 값만을 다룰 때처럼 모든 성분의 값들을 일일이 확인하면서 데이터가 맞는지, 연산이 잘 되었는지 확인하는 게 불가능하다. <br>그래서 주요 연산 방법을 확실하게 익혀둔 다음에 연산 시 shape 변화를 확인하는게 가장 좋은 방법이다. \n",
    "\n",
    "\n",
    "\n",
    "### 2. Broadcasting <br>\n",
    "\n",
    "Numpy에는 특이한 연산이 존재하는데 바로 **broadcasting**이라는 것이다. <br>\n",
    "아래 예시를 보자. `a`는 vector이고 `b`는 scalar인데 연산이 잘 된다. 이게 안 이상하다면 아래 예제를 보자. <br>\n",
    "\n",
    "`a, b`는 모두 (1,3) shape의 matrix이다. element wise product를 하니 각각의 성분을 곱한 값이 나왔다. <br>\n",
    "그 아래는 `b`를 transpose한 후에 a랑 마찬가지로 element wise product를 했다. 같은 결과가 나왔다. <br>\n",
    "\n",
    "이런 식의 결과를 나오게 하는 걸 **broadcasting** 이라고 하는데 연산의 편리함? 을 위해서 shape가 완전 일치하지 않더라도 <br>\n",
    "특정 규칙에 의해서 결과가 나오게 만들어주는 것을 말한다. (***진짜 효율적이다.***)\n",
    "\n",
    "사용 예시는 ***tensor에 scalar를 더했을 때 scalar 값이 모든 성분에 다 더하거나 곱하거나 할 수 있다. .***, \n",
    "***N-D tensor와 (N-M)-D tensor가 있을 때 shape이 차원이 큰 쪽에 딱 맞게 속하면 모든 성분이 다 더해지거나 곱하거나 할 수 있다.***\n",
    "일단 말로 이해하기 어려운 개념이라 완전 자세히 알 필요도 없고 몇 가지만 알면 된다. 쓰면서 배우자.\n",
    "\n",
    "```python\n",
    ">>> a = np.array([1, 2, 3])\n",
    ">>> b = 2\n",
    ">>> a * b\n",
    ": array([2, 4, 6])\n",
    "\n",
    ">>> a = np.array([1.0, 2.0, 3.0])\n",
    ">>> b = np.array([2.0, 2.0, 2.0])\n",
    ">>> a * b\n",
    ": array([ 2.,  4.,  6.])\n",
    "\n",
    ">>> a = np.array([1.0, 2.0, 3.0])\n",
    ">>> b = np.array([2.0, 2.0, 2.0])\n",
    ">>> a * b.T\n",
    ": array([ 2.,  4.,  6.])\n",
    "```\n",
    "\n",
    "\n",
    "### 3. 코드 tip\n",
    "\n",
    "위에서 shape와 broadcasting을 훑어봤다. 가장 헷갈리는 두가지인데 수식을 numpy로 표현할 때 tip이 있다. (***Andrew Ng 교수님이 다른 수업에서 주심***) <br> \n",
    "\n",
    "먼저, vector는 무조건 2-D tensor로 선언한다. 위에서 봤듯이 2-D tensor로 선언도 가능한데 이렇게 되면 row(행)으로도 쓸 수 있고 column(열)로도 쓸 수 있어서(**broadcasting**) 편하긴 한데 엄청 헷갈린다. 그러므로 무조건 내 사용 용도에 딱 맞게 행이면 행, 열이면 열로 지정해서 사용하자. \n",
    "\n",
    "- 행 : (1 x N) shape \n",
    "- 열 : (M x 1) shape \n",
    "\n",
    "두번째는 처음에는 모든 결과값의 shape를 출력하자. 아래 예를 보자. <br>\n",
    "`X`의 shape가 (2,3), `theta`는 (3,1) 이므로 dot product를 취하면 `y`의 shape은 (2,1)이 나온다. 수식이 조금 복잡해지면 \n",
    "헷갈리니까 습관을 들이도록 하자.\n",
    "\n",
    "```python\n",
    ">>> X = np.array([[1,1,3], [2,2,3]])\n",
    ">>> print(X.shape)\n",
    ": (2, 3)\n",
    ">>> theta = np.array([[2],[3],[1]])\n",
    ">>> print(theta.shape)\n",
    ": (3, 1)\n",
    ">>> y = np.dot(X, theta) \n",
    ">>> print(y.shape)\n",
    ": (2, 1)\n",
    "```\n",
    "\n",
    "### 4. 데이터 생성\n",
    "\n",
    "주로 확인하는 작업을 거칠 때 여러가지 데이터 생성 방법을 통해서 한다. 대표적인 몇 가지 방법을 소개하도록 하겠다. \n",
    "\n",
    "- 랜덤 데이터 샘플링 : **아무 생각없이 뽑고 싶을 때**나 정규 분포 데이터가 있으면 좋을 때 쓴다. \n",
    "- 랜덤 index 샘플링 : 가지고 있는 데이터에서 랜덤하게 index를 뽑고 싶을 때 쓴다. \n",
    "- 일정한 간격 데이터 샘플링 : 그래프 그려줄 때 주로 사용한다. \n",
    "\n",
    "\n",
    "\n",
    "**[단어 정리] **\n",
    "\n",
    "- element wise product : 각각 매칭되는 성분끼리의 곱\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "출처 :\n",
    "1. [Tensorflowkorea - ranks, shapes, type](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html)\n",
    "2. [Numpy - broadcasting](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "D2_tensor = np.array([[1,1]])\n",
    "\n",
    "D2_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,1,3], [2,2,3]])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.array([[2],[3],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8],\n",
       "       [13]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
