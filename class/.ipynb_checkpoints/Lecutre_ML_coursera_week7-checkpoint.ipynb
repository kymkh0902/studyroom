{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Week #7\n",
    "\n",
    "7주차 강의에서는 6주차 내용의 연장선으로 머신러닝을 실제로 적용할 때의 몇 가지 포인트에 대해서 부연 설명하고 있다.\n",
    "\n",
    "### Spam 구별 모델을 구축하려면?\n",
    "\n",
    "먼저, 앞에서 배운 내용을 spam/non-spam 구별의 예시를 통해 다시 한 번 되짚어보자. \n",
    "\n",
    "0. 문제를 정의한다 - spam, non-spam 거르기 \n",
    "1. 문제 해결을 위한 데이터를 준비한다.    - 이메일 데이터 수집\n",
    "2. 데이터의 특징을 파악한다.            - 단어들의 출현 빈도 파악, 단어 간의 연관성 파악, 철자가 틀린 단어 파악\n",
    "3. 데이터가 많은 경우 feature를 걸러낸다. - 3에서 정의한 내용을 *수학적으로* 나타낸다. (*one-hot encoding...*)\n",
    "4. 데이터를 train/val/test로 나눈다.  - 데이터를 나눈다. \n",
    "5. 모델을 여러 개 선정한다.            - neural network, logistic regression 등 classification을 위한 모델 선정 \n",
    "6. hyperparameter를 선정하고 학습한다. - 모델에 맞추어 학습한다. \n",
    "7. 결과를 본다.                      - 노가다\n",
    "\n",
    "큰 줄기는 위와 같다. 문제를 정의한 뒤 우리가 원하는 목적(구별, 값 예측..)에 따라 데이터의 특징을 살펴서 이를 **수학적으로 어떻게 나타낼 지** 정한다. 그리고 이 후에는 수업 시간에 가장 많이 다룬 데이터를 나누고 학습하는 과정이 진행된다. \n",
    "\n",
    "모델은 선택하고 hyperparameter 별로 학습시킨 뒤 성능을 비교해보면 되니 이 과정이 자동적으로 이뤄진다고 가정했을 때 다른 부분들을 살펴보자.\n",
    "\n",
    "Spam 구분의 문제에 대해서 우리가 잘 학습시키려고 하면 무엇이 필요할까?\n",
    "\n",
    "- Spam의 특징도 제각각일 것이므로 많은 특징들을 나타내는 다양한 데이터가 필요하다.\n",
    "- 제목 내용으로 바로 알 수 있거나 내용 중 철자 오기나, 특정한 단어(*19금, 대출..*)등 을 통해 구별할 수 있다. \n",
    "\n",
    "자, 이제 위에서 정한 내용대로 학습을 했다고 하자. 95%의 정확도로 spam 검출이 가능하다고 했을 떄, 이제 해야 할 일은 뭘까?\n",
    "\n",
    "-> 나머지 5%에 대한 에러를 분석해서(**Error Analysis**)를 해서 개선의 여지를 찾아야 한다!!\n",
    "\n",
    "### Error Analysis\n",
    "\n",
    "시험에서 틀린 항목에 대해서 왜 틀렸는지에 대해 분석하는 것처럼 머신러닝의 학습 시에도 \n",
    "틀린 데이터에 대해서 오답들이 어떤 공통적인 특징을 가지고 있는지 분석해서 이를 반영해주어야 개선할 수 있다.\n",
    "\n",
    "\n",
    "### 평가 방법 (Metrics)\n",
    "\n",
    "지금까지 다룬 평가 방법은 Euclidean distance(집 값 예측), Accuracy(숫자 예측)이 있다. <br>\n",
    "Euclidean distance는 두 점을 $p, q$라고 했을 때, 점 사이의 거리를 $d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + ...}$ 해당 식으로 정의한다. \n",
    "\n",
    "Accuracy는 $\\frac {예측\\ 성공\\ 개수} {전체\\ 예측한\\ 개수}$ 로 나타낸다. \n",
    "\n",
    "#### 평가 방법이 중요한 이유 \n",
    "\n",
    "Metrics이 중요한 이유는 우리가 어떤 기준을 가지고 평가하느냐에 따라서 모델이 우리가 원하는 결과를 얻는지 못 얻는지를 알 수 있기 때문이다. \n",
    "\n",
    "예시를 들어보면 환자들이 1000명이 암 검사를 받았다고 해보자. 이 때, 10명이 실제로 암에 걸린 사람들이다. 모델은 모든 사람들이 암이 없다고 예측했다고 하자. 이 때 Accuracy는? \n",
    "99%이다. 이런 식으로 99%면 높다고 잘못 생각할 수 있다. 하지만 실제는 하나도 맞추지 못하는 무능한 모델을 사용한 것이고 이 때, 우리는 평가 방법이 뭔가 잘못되었다는 것을 알 수 있다.\n",
    "\n",
    "그럼 어떻게 평가해야 할까? 실제 암이 있는 사람들 중에 몇 명이나 올바르게 예측했는지를 봐야한다.(**Recall**) 아니면 암이 있다고 예측한 사람 중에 실제로 암이 있는 사람의 비율을 예측해야 한다. (**Precision**)\n",
    "\n",
    "그럼 위 두 방법에서는 어떤 것을 선택해야 할까? 이 때에는 어떤 상황을 더 중요하게 생각하는지에 대한 고민이 필요하다. ***암이 안 걸린 사람에게 암 진단하는게 risk가 클까? 아니면 암이 걸린 사람을 못 맞췄을 때 risk가 클까?*** 전자라고 하면, Recall을, 후자라고 하면 Precision을 택하면 된다. \n",
    "\n",
    "Recall을 사용했을 때를 생각해보자. 전부다 암일 것이라고 예측해보자. 그럼 Recall은?\n",
    "100%이다. Precision은? 1%이다. 즉, Recall이 높다는 뜻은 ***암이 아주 치명적인 병이므로 느슨하게 예측해서 암일거 같으면 전부다 암으로 진단을 한다. ***\n",
    "\n",
    "Precision을 사용했을 때를 생각해보자. 5명이 암이라고 예측했는데 5명 모두 맞았다.  Precision은? 100%이다. 즉, Precision이 높다는 뜻은 전체 암에 걸린 사람의 수는 고려하지 않고 예측한 부분에 대해서만 얼마나 정확한지 본다. 즉, Precision이 높으면 암이 있다고 진단 받았을 때 **정말 암에 걸렸을 것**이지만 ***실제 암이 있어도 없다고 할 확률도 높다.***\n",
    "\n",
    "이처럼, Precision과 Recall은 어느 정도 trade-off 관계에 있다. 그러므로 둘을 모두 고려하고 싶을 떄에는 섞은 F1 score를 사용하면 된다. \n",
    "\n",
    "*실제 병원에서는 아마 Recall에 더 힘을 싣는다. 왜냐면 암이 걸렸다고 하더라도 다시 검사를 받는 경우가 많기 때문인데, 암이 걸려있더라도 발견하지 못하면 더 큰일나기 때문이다.*\n",
    "\n",
    "\n",
    "- $Precision = \\frac {TP} {TP+FP}$\n",
    "- $Recall =  \\frac {TP} {TP+FN}$\n",
    "- $Accuracy = \\frac {TP+TN} {TP+TN+FP+FN}$\n",
    "- $F_1\\ Score = \\frac {2PR} {P+R}$ $(P:\\ Precision,\\ R:\\ Recall)$\n",
    "\n",
    "![precision, recall, accuracy](https://qph.ec.quoracdn.net/main-qimg-5cdc951ada50a9fe2c65e6e5ec3d9bb4)\n",
    "\n",
    "\n",
    "#### Precision, Recall 조절 방법?\n",
    "\n",
    "그럼 어떻게 trade-off 관계인 Recall, Precision 값을 조절할 수 있을까? 방법은 우리가 결정하는 기준을 바꿔주면 된다. Logistic regression에서 우리는 기준을 0.5로 두고 0.5 이상은 1, 0.5 미만은 0으로 처리했다. 만약 0.5가 아니라 0.99로 두면?\n",
    "\n",
    "Precision이 엄청 높아질 것이다. 왜냐면 0.01을 뚫고 맞춘 값은 정답일 가능성이 매~우 높을 것이기 때문이다. \n",
    "그럼 반대로 0.01로 기준값을 두면? Recall이 엄청 높아질 것이다. 왜냐면 죄다 정답이라고 예측할 것이고 그 중에는 진짜 정답도 섞여있을 것이기 때문이다. \n",
    "\n",
    "![precision vs recall](../pictures/precision_recall.png)\n",
    "\n",
    "### 데이터 양과 모델에 대한 고찰\n",
    "\n",
    "마지막 내용에는 모델 별로 데이터 양을 증가시켰을 때의 성능을 보여준다. 여기서 말하고자하는 내용은 아래와 같다.\n",
    "\n",
    "1. 데이터의 양이 모델의 성능을 크게 증가시킬 수 있다.\n",
    "2. 데이터가 많아질수록 모델들의 성능은 전부 비슷해지는데, 이는 적은 데이터에도 효과적으로 작동하는 모델이 중요하다는 것을 보여준다. (*시간과 돈..*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
