{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning week #6\n",
    "\n",
    "###  Advice for applying Machine Learning\n",
    "\n",
    "이전 장까지 우리는 머신러닝의 supervised learning의 대표적인 모델들(*linear regression, logistic regression, neural network*)들을 배웠으며 모델이 선정되어 있다고 가정한 상태에서 데이터를 학습하는 과정을 주로 배웠다.\n",
    "\n",
    "이번 장에서는 머신러닝을 이용해서 데이터에 맞는 모델을 선정하고 구축할 때 필요한 조언을 해주는데 어떤 어려움들이 있는지 강의를 통해 살펴보자.\n",
    "\n",
    "\n",
    "### 전반적인 머신러닝 문제해결 과정\n",
    "\n",
    "우리가 어떤 문제를 머신러닝으로 풀 때의 과정은 아래와 같다.\n",
    "\n",
    "0. 문제를 정의한다. \n",
    "1. 문제 해결을 위한 데이터를 준비한다. \n",
    "2. 데이터의 특징을 파악한다.(*시각화 사용, 통계적으로 나타내보기*)\n",
    "3. 데이터가 많은 경우 feature를 걸러낸다.(*통계적인 기법*)\n",
    "4. 데이터를 train/val/test로 나눈다. \n",
    "5. 모델을 여러 개 선정한다. \n",
    "6. hyperparameter를 선정하고 학습한다.\n",
    "7. 결과를 본다.\n",
    "\n",
    "1~3까지의 내용이 매우 중요하지만 단순한 문제를 접근했거나 내가 너무 잘 알고 있는 domain이라서 잘 설정했다고 가정해보자. <br>\n",
    "이제 4~7까지의 과정만 남았고 **우리가 지금까지 배운 건 6번 과정 밖에 없다.** 골라져있는 모델을 적절한 데이터로 잘 학습된 것이 전부이고 \n",
    "실제로 임의의 데이터로 학습을 할 때는 많은 복잡한 과정을 거치면서 모델을 구축하게 된다. 하나씩 살펴보도록 하자.\n",
    "\n",
    "\n",
    "### 머신러닝의 큰 문제 \n",
    "\n",
    "1. `overfitting:` 모델이 너무 복잡해서 training 데이터에 완전히 맞춰진다.(*암기한다.*) 다른 test 데이터를 입력해줬을 때는 성능이 좋지 않게 나온다. <br> (***high variance, low bias***)\n",
    "2. `underfitting:` 모델이 너무 단순해서 training 데이터에 대해서도 잘 학습이 이루어지지 않는다. test, training 모두 성능이 좋지 않다. <br> (***low variance, high bias***)\n",
    "\n",
    "크게 머신러닝에는 overfitting과 underfitting의 문제가 있다.(week4 참조!) 보통 위 4~7의 과정을 진행한 뒤에 모델을 돌리면 두 가지 중 하나의 문제가 발생할 것이며 이를 해결해가는 과정이 가장 시간이 많이 드는 작업이다. 그래서 각각의 항목 별로 어떤 직관을 통해서 문제를 접근해야 할 지 배워보도록 하자.\n",
    "\n",
    "### 평가 방법 \n",
    "\n",
    "문제가 있다는 건 알았는데 어떻게 평가했을 때 문제가 있는지는 아직 안 배운 듯하다. 지금까지는 train 데이터로 모델을 학습하고 또 다시 같은 데이터로 평가했다. 하지만 ***우리가 원하는 건 아예 모르는 데이터를 입력했을 때 모델의 성능이 궁금하므로 동일하게 평가해야한다.*** 근데 평가를 위한 데이터도 정답이 있어야 평가가 가능하니 우리가 가진 데이터를 쪼개서 사용한다.\n",
    "\n",
    "비율은 `train:validation:test = 6:2:2`로 가져가며 각자의 역할이 있다. \n",
    "1. `train:` 학습 용도\n",
    "2. `validation:` model의 hyperparameter 선정 용도\n",
    "3. `test:` 최종적으로 성능 확인 용도(***정말 마지막에만 사용한다. 시험이 끝나고 채점하는 답과 같다.***) <br>\n",
    "\n",
    "아직 어떤 모델의 parameter가 가장 좋은지 모르는데, 이에 대한 성능 평가를 하려면 train 시키지 않은 데이터가 필요해서 validation 데이터를 따로 만들어 주어 최적의 모델을 찾는 것이고 그 다음에 최종적으로 평가를 해서 모델이 어느 정도 성능을 내는지 확인한다.\n",
    "\n",
    "### 평가 결과\n",
    "\n",
    "모델을 학습하면 아래 그림과 같이 우리가 가진 데이터를 너무 잘 나타내거나 아니면 조금 부족해보이거나 할 것이다. <br>\n",
    "bias, variance에 대해서 너무 깊이 고민하지 말고 그냥 **복잡도**라는 측면에서 모델을 보도록 하자. 모델이 너무 복잡해지면 train 데이터를 외워버려서 오른쪽 그래프처럼 쓸모 없어지고 그렇다고 너무 단순하면 왼쪽 그래프처럼 애매..해진다. 이 균형을 잡은게 가운데 그래프인데, ***그럼 무엇을 보고 균형이 잡혀있다는 것을 알 수 있을까? 어떻게 우리의 모델이 괜찮은지 진단할 수 있을까?***\n",
    "![bias_vs_variance](../pictures/bias_vs_variance.png)\n",
    "<center>*&lt;출처: [coursera - machine learning lecture10 note](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning.html)&gt;*</center>\n",
    "\n",
    "### 문제 진단\n",
    "\n",
    "머신러닝은 크게 **1) 모델의 복잡도, 2) 데이터의 양** 으로 나누어서 현 모델의 문제를 진단 하고 이에 따라 접근 방식을 달리한다. <br>\n",
    "\n",
    "먼저 ***모델의 복잡도***에 대해서 살펴보도록 하자. \n",
    "아래 그래프는 모델의 복잡도에 따라서 성능이 어떻게 변하는 지 보여준다. 그래프를 보면 x축은 모델의 복잡도를 나타내고, y축은 error를 나타낸다. 쉽게 보면 모델이 복잡해질 수록 train error는 계속 줄어들고 validation error는 어느 정도 줄어들다 증가하는 경향을 보인다. 위의 그래프 내용을 잘 나타낸다고 볼 수 있다. 학습을 진행하다 어느 정도 적절한 수준에 도달하면 validation error가 증가하기 시작해서 이 즈음에 해당되는 모델을 선정하면 될 것이다.\n",
    "![graph](../pictures/graph.png)\n",
    "<center>*&lt;출처: [coursera - machine learning lecture10 note](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning.html)&gt;*</center>\n",
    "\n",
    "다음은 ***데이터의 양***에 대해서 살펴보자. 아래 그래프는 training 데이터 수에 따라 성능이 어떻게 변하는 지 보여준다. <br> 데이터 수에 따라서 어떻게 될까? 먼저, 데이터가 적은 경우에는 모델이 단순한 모델로 쉽게 학습이 가능하고 train 데이터에 대해 매우 좋은 성능을 낼 것이다. 하지만, 우리가 모르는 test 데이터에 대해서는 성능이 안 좋을 것이라고 예상할 수 있다. 왜냐면 몇 개의 샘플을 보고 일반화를 하는 오류를 범한 것으로 생각할 수 있기 때문이다. \n",
    "\n",
    "그럼 데이터가 많은 경우에는? train 데이터에 대해서 많은 점들을 모델로 나타내야 하므로 좀 더 복잡한 모델이 필요하게 될 것이고 train 에러도 커질 것이다. 하지만, test 데이터에 대해서는 어느 정도 샘플을 많이 보았기 때문에 일반화가 되어 전자의 모델보단 성능이 좋게 나올 것으로 볼 수 있다.\n",
    "\n",
    "위 내용을 나타낸 것이 아래 그래프이며 데이터는 많으면 많을수록 좋다는 결론을 내릴 수 있지만 일정 수준에 도달하면(*적당히 많으면*) 더 늘리는게 크게 도움이 안 된다는 것을 알 수 있다.\n",
    "![learning_curve](../pictures/learning_curv.png)\n",
    "<center>*&lt;출처: [coursera - machine learning lecture10 note](http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning.html)&gt;*</center>\n",
    "\n",
    "\n",
    "\n",
    "### 문제 해결 방법\n",
    "\n",
    "위에서 모델을 평가하고, 보통 초기 학습 시에 어떤 결과가 나오는지 대략적으로 배웠으며 크게 어떤 식으로 진단하는지에 대해서 배웠다. <br>\n",
    "이제 얘기할 내용은 위에서 진단한 내용에 대해서 할 수 있는 방안을 얘기하는 것이다. \n",
    "\n",
    "1. 모델의 복잡도 \n",
    "    - 좀 더 복잡한(단순한) 모델의 설정(1차원 &#10231; 다차원)\n",
    "    - feature수 감소(증가)\n",
    "    - lambda값 감소(증가)\n",
    "2. 데이터의 양  \n",
    "    - 추가 데이터 확보(*시간과 돈*)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
