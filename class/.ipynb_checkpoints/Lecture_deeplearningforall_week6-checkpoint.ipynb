{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모두를 위한 딥러닝 #6\n",
    "\n",
    "지난 시간에 RNN의 개념에 대해 살펴봤고 이제 어떤 식으로 응용할 수 있는지 간단하게 살펴보도록 하자.\n",
    "\n",
    "### 학습 순서\n",
    "- Seq2Seq2 모델 살펴보기 \n",
    "    - Encoder: input을 받는 곳\n",
    "    - Decoder: input에서의 마지막 hidden state를 받아서 이를 다시 RNN을 돌려서 sequence를 만드는 곳 \n",
    "    - Attention: input의 각각의 hidden state의 값들을 가중치를 매겨서 취합한 뒤에 Decoder의 각 hidden state에 반영해서 최종 output을 만든다. \n",
    "- 학습 목표: toy code로 encoder로 문자열을 집어넣은 뒤 decoder로 문자열이 거꾸로 나오게 만들어주는 모델을 학습시켜본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seq2seq](https://www.tensorflow.org/versions/master/images/seq2seq/attention_mechanism.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 데이터 전처리\n",
    "\n",
    "0. `load_data`: 텍스트를 불러온다. \n",
    "1. `extract_character_vocab`: 문자로 된 사전을 만든다.\n",
    "2. `pad_sentence_batch`: batch로 데이터를 불러왔을 때 정해진 길이에 미달하면 padding을 해준다. \n",
    "3. `get_batches`: 데이터로부터 batch를 가져온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 문자열의 길이가 다 제각각이므로 일정한 길이에 맞춰서 0으로 padding을 해준다. \n",
    "PAD = 0\n",
    "# 사전에 없는 문자열은 unknown(UNK)로 받도록 하기 위해 1로 지정해준다.\n",
    "UNK = 1\n",
    "# 학습을 위해서 시작 문자를 GO라고 지정해준다. (모델은 GO를 받으면 항상 시작하도록 학습함. decoder 처음에 입력 값으로 주게 된다.)\n",
    "GO = 2\n",
    "# 학습을 위해서 끝 문자를 EOS라고 지정해준다. (모델이 EOS를 받으면 문자열 생성을 중단하도록 학습함.)\n",
    "EOS = 3\n",
    "start_token = GO\n",
    "end_token = EOS\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_character_vocab(data):\n",
    "    special_words = ['<PAD>', '<UNK>', '<GO>', '<EOS>']\n",
    "    set_words = set([character for line in data.split('\\n') for character in line])\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(targets, sources, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources) // batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "            \n",
    "        yield pad_targets_batch, pad_sources_batch, np.array(pad_targets_lengths), np.array(pad_source_lengths)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 불러온다.\n",
    "source_sentences = load_data('./datasets/letters_source.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열:숫자, 숫자:문자열 의 사전을 만든다.\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_int_to_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_letter_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열을 숫자로 변환한다.\n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<UNK>']) for letter in line]\\\n",
    "                     for line in source_sentences.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "valid_source = source_letter_ids[:config.batch_size]\n",
    "valid_target = [list(reversed(i)) + [3] for i in valid_source]\n",
    "(valid_targets_batch, valid_sources_batch, valid_targets_lengths, valid_sources_lengths) = \\\n",
    "    next(get_batches(valid_target, valid_source, config.batch_size, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. config\n",
    "1. `rnn_size`: encoder, decoder의 hidden_state의 크기이다. \n",
    "3. `embedding_size`: encoder, decoder가 각각 다르게 가져가며 input을 몇 개의 차원 vector로 표현할 지 결정한다. (크면 클 수록 많은 정보를 다양하게 표현할 수 있지만 연산량이 많아진다. 정보가 많다면 클 수록 좋지만 지금 다루는 건 간단한 예제이므로 작게 둔다.) \n",
    "4. `source_vocab`: 단어 개수에 해당되는 항으로 embedding 할 때 단어에 매칭해서 vector로 변환해야 하므로 embedding matrix 크기를 결정할 때 필요하다. 우리 예제에서는 문자 개수라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.epochs = 15\n",
    "        # Batch Size\n",
    "        self.batch_size = 128\n",
    "        # RNN Size\n",
    "        self.rnn_size = 50\n",
    "        # Embedding Size\n",
    "        self.encoding_embedding_size = 15\n",
    "        self.decoding_embedding_size = 15\n",
    "        # Learning Rate\n",
    "        self.learning_rate = 0.001\n",
    "        self.source_vocab = 30\n",
    "        self.max_decode_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model\n",
    "0. `__init__`: mode는 decode, train 모드 2가지가 있다. 이 때 encoder의 입력 값은 같지만 decoder에서의 값이 많이 달라진다.\n",
    "    - train: 학습한다.\n",
    "    - decode: 입력 값에 대한 예측을 한다. (test로 보면 됨)\n",
    "1. `add_placeholders`: \n",
    "    - `[batch_size, max_time_step]` 의 크기의 encoder, decoder input이 들어간다. 3-d tensor가 아닌데, 이 값이 embedding matrix를 통과해서 3-d tensor가 될 것이다.\n",
    "    - train 일 때, decoder input에는 조금 수정이 가해진다. 위 그림에서 보면 &lt;s&gt;(**start token**)가 decoder input에 더해지는 것을 볼 수 있다. 또, &lt;/s&gt;(**end token**)이 decoder output(**decoder input을 한 칸 미룬 값**)에 더해지는 것도 볼 수 있는데 이를 구현해줘야 한다.\n",
    "2. `build_encoder`: Bi-directional RNN으로 구현해준다. 양 방향 모두 LSTM을 사용하며 주의할 점은 양 쪽의 데이터를 합쳐서 활용해야 한다는 점이다.\n",
    "3. `build_decoder`: \n",
    "    - decoder: LSTM을 사용하며 encoder에서 넘어온 값을 Attention을 통과시키고 decoder에서 나온 값과 합친다. 그리고 이 값을 Dense를 통과시켜서 최종 output(**사전에 대한 softmax 예측**)을 내놓게 된다.\n",
    "    - loss: padding을 고려해서 backpropagation을 해야 하므로 mask에 대한 정보를 고려한 뒤 loss를 cross entropy로 구한다.\n",
    "    - optimizer: RNN은 gradient가 튀는 경우가 많아서 이를 방지하기 위해서 gradient clipping을 해준다. (**gradient의 max 값을 지정해서 넘으면 max 값을 갖도록 한다.**)\n",
    "    - inference: 모드가 **decode**일 때 예측을 해야 하는데, 이 때 **greedy**(문자열을 순서대로 예측할 때 가장 높은 확률을 갖는 값들로만 연속적으로 예측한다.)한 방법을 사용해서 예측한다. \n",
    "4. `train`, `eval`: encoder, decoder에 넣어줄 데이터의 값과 길이(padding을 확인하기 위함.)를 전달해주면 학습하고 예측할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Seq2Seq + Attention model\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, config, mode):\n",
    "        self.config = config\n",
    "        self.mode = mode\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        # encoder_inputs : [batch_size, max_time_steps]\n",
    "        self.encoder_inputs = tf.placeholder(\n",
    "            dtype=tf.int32, shape=(None, None), name='encoder_inputs')\n",
    "        # encoder_inputs_length : [batch_size]\n",
    "        self.encoder_inputs_length = tf.placeholder(\n",
    "            dtype=tf.int32, shape=(None,), name='encoder_inputs_length')\n",
    "        # get dynamic batch_size\n",
    "        self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "\n",
    "        # train일 때 decoder가 필요한 데이터에 수정이 필요하다.\n",
    "        if self.mode == 'train':\n",
    "            # decoder_inputs : [batch_size, max_time_steps]\n",
    "            self.decoder_inputs = tf.placeholder(\n",
    "                dtype=tf.int32, shape=(None, None), name='decoder_inputs')\n",
    "            # decoder_inputs_length: [batch_size]\n",
    "            self.decoder_inputs_length = tf.placeholder(\n",
    "                dtype=tf.int32, shape=(None,), name='decoder_inputs_length')\n",
    "\n",
    "            decoder_start_token = tf.ones(\n",
    "                shape=[self.batch_size, 1], dtype=tf.int32) * start_token\n",
    "            decoder_end_token = tf.ones(\n",
    "                shape=[self.batch_size, 1], dtype=tf.int32) * end_token\n",
    "\n",
    "            # decoder_inputs_train: [batch_size , max_time_steps + 1]\n",
    "            # insert _GO symbol in front of each decoder input\n",
    "            self.decoder_inputs_train = tf.concat([decoder_start_token,\n",
    "                                                  self.decoder_inputs], axis=1)\n",
    "\n",
    "            # decoder_inputs_length_train: [batch_size]\n",
    "            self.decoder_inputs_length_train = self.decoder_inputs_length + 1\n",
    "\n",
    "            # decoder_targets_train: [batch_size, max_time_steps + 1]\n",
    "            # insert EOS symbol at the end of each decoder input\n",
    "            self.decoder_targets_train = tf.concat([self.decoder_inputs,\n",
    "                                                   decoder_end_token], axis=1)\n",
    "\n",
    "    def build_encoder(self):\n",
    "        # ENCODER (Bi-directional\n",
    "        encoder_embeddings = tf.get_variable(\n",
    "            name='embeddings', shape=[self.config.source_vocab, self.config.encoding_embedding_size])\n",
    "        encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.encoder_inputs)\n",
    "\n",
    "        # Bi-RNN\n",
    "        encoder_cell_fw = tf.contrib.rnn.BasicLSTMCell(self.config.rnn_size)\n",
    "        encoder_cell_bw = tf.contrib.rnn.BasicLSTMCell(self.config.rnn_size)\n",
    "        encoder_out, encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "            encoder_cell_fw, encoder_cell_bw, encoder_embedded, self.encoder_inputs_length, dtype=tf.float32)\n",
    "        encoder_c_state = tf.concat([encoder_state[0].c, encoder_state[1].c], -1)\n",
    "        encoder_h_state = tf.concat([encoder_state[0].h, encoder_state[1].h], -1)\n",
    "        self.encoder_state = tf.contrib.rnn.LSTMStateTuple(encoder_c_state, encoder_h_state)\n",
    "        self.encoder_out = tf.concat(encoder_out, -1)\n",
    "\n",
    "    def build_decoder(self):\n",
    "        # ATTENTION\n",
    "        decoder_cell = tf.contrib.rnn.BasicLSTMCell(self.config.rnn_size * 2)\n",
    "\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units=self.config.rnn_size * 2,\n",
    "            memory=self.encoder_out,\n",
    "            memory_sequence_length=self.encoder_inputs_length)\n",
    "\n",
    "        # attention wrapper\n",
    "        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell=decoder_cell,\n",
    "            attention_mechanism=attention_mechanism,\n",
    "            attention_layer_size=self.config.rnn_size * 2)\n",
    "\n",
    "        decoder_initial_state = decoder_cell.zero_state(\n",
    "            self.config.batch_size, tf.float32).clone(cell_state=self.encoder_state)\n",
    "\n",
    "        # DECODER\n",
    "        Y_vocab_size = self.config.source_vocab\n",
    "        output_layer = Dense(self.config.source_vocab, name='output_projection')\n",
    "        self.decoder_embedding = tf.Variable(\n",
    "            tf.random_uniform([Y_vocab_size, self.config.decoding_embedding_size], -1.0, 1.0),\n",
    "            name='decoder_embedding')\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            decoder_embedded = tf.nn.embedding_lookup(self.decoder_embedding, self.decoder_inputs_train)\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                inputs=decoder_embedded,\n",
    "                sequence_length=self.decoder_inputs_length_train,\n",
    "                time_major=False,\n",
    "                name='training_helper')\n",
    "\n",
    "            # basic decoder\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell=decoder_cell,\n",
    "                helper=training_helper,\n",
    "                initial_state=decoder_initial_state,\n",
    "                output_layer=output_layer)\n",
    "\n",
    "            self.max_decoder_length = tf.reduce_max(self.decoder_inputs_length_train)\n",
    "            training_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder=training_decoder,\n",
    "                impute_finished=True,\n",
    "                maximum_iterations=self.max_decoder_length)[0]\n",
    "            training_logits = tf.identity(\n",
    "                training_decoder_output.rnn_output, name='logits')\n",
    "\n",
    "            # LOSS\n",
    "            masks = tf.sequence_mask(self.decoder_inputs_length_train, self.max_decoder_length, dtype=tf.float32, name='mask')\n",
    "            self.loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                logits=training_logits, targets=self.decoder_targets_train, weights=masks)\n",
    "\n",
    "            # BACKWARD\n",
    "            params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.loss, params)\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "            self.train_op = tf.train.AdamOptimizer().apply_gradients(\n",
    "                zip(clipped_gradients, params))\n",
    "\n",
    "        # INFERENCE\n",
    "        elif self.mode == 'inference':\n",
    "            start_tokens = tf.ones([self.config.batch_size, ], dtype=tf.int32) * start_token\n",
    "            end_tokens = end_token\n",
    "\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                embedding=self.decoder_embedding, start_tokens=start_tokens, end_token=end_tokens)\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell=decoder_cell,\n",
    "                helper=inference_helper,\n",
    "                initial_state=decoder_initial_state,\n",
    "                output_layer=output_layer)\n",
    "            inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(\n",
    "                inference_decoder, impute_finished=True, maximum_iterations=self.config.max_decode_step)[0]\n",
    "            self.inference_logits = tf.identity(\n",
    "                inference_decoder_output.sample_id, name='predictions')\n",
    "\n",
    "    # TRAIN STEP\n",
    "    def train(self, sess, encoder_inputs, encoder_inputs_length,\n",
    "              decoder_inputs, decoder_inputs_length):\n",
    "        \"\"\"\n",
    "        :param sess: session\n",
    "        :param encoder_inputs:\n",
    "        :param encoder_inputs_length:\n",
    "        :param decoder_inputs:\n",
    "        :param decoder_inputs_length:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # train인지 check\n",
    "        if self.mode.lower() != 'train':\n",
    "            raise ValueError(\"train step can only be operated in train mode\")\n",
    "        input_feed = self.check_feeds(encoder_inputs, encoder_inputs_length,\n",
    "                                      decoder_inputs, decoder_inputs_length, False)\n",
    "\n",
    "        output_feed = [self.train_op, self.loss]\n",
    "        outputs = sess.run(output_feed, input_feed)\n",
    "        return outputs[1]\n",
    "\n",
    "    # EVAL STEP\n",
    "    def eval(self, sess, encoder_inputs, encoder_inputs_length,\n",
    "              decoder_inputs, decoder_inputs_length):\n",
    "        \"\"\"\n",
    "        :param sess: session\n",
    "        :param encoder_inputs:\n",
    "        :param encoder_inputs_length:\n",
    "        :param decoder_inputs:\n",
    "        :param decoder_inputs_length:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # train인지 check\n",
    "        if self.mode.lower() != 'train':\n",
    "            raise ValueError(\"train step can only be operated in train mode\")\n",
    "        input_feed = self.check_feeds(encoder_inputs, encoder_inputs_length,\n",
    "                                      decoder_inputs, decoder_inputs_length, False)\n",
    "\n",
    "        output_feed = [self.loss]\n",
    "        outputs = sess.run(output_feed, input_feed)\n",
    "        return outputs[0]\n",
    "\n",
    "\n",
    "    def check_feeds(self, encoder_inputs, encoder_inputs_length,\n",
    "                    decoder_inputs, decoder_inputs_length, decode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          encoder_inputs: a numpy int matrix of [batch_size, max_source_time_steps]\n",
    "              to feed as encoder inputs\n",
    "          encoder_inputs_length: a numpy int vector of [batch_size]\n",
    "              to feed as sequence lengths for each element in the given batch\n",
    "          decoder_inputs: a numpy int matrix of [batch_size, max_target_time_steps]\n",
    "              to feed as decoder inputs\n",
    "          decoder_inputs_length: a numpy int vector of [batch_size]\n",
    "              to feed as sequence lengths for each element in the given batch\n",
    "          decode: a scalar boolean that indicates inference mode\n",
    "        Returns:\n",
    "          A feed for the model that consists of encoder_inputs, encoder_inputs_length,\n",
    "          decoder_inputs, decoder_inputs_length\n",
    "        \"\"\"\n",
    "\n",
    "        input_batch_size = encoder_inputs.shape[0]\n",
    "        if input_batch_size != encoder_inputs_length.shape[0]:\n",
    "            raise ValueError(\"Encoder inputs and their lengths must be equal in their \"\n",
    "                             \"batch_size, %d != %d\" % (input_batch_size, encoder_inputs_length.shape[0]))\n",
    "\n",
    "        if not decode:\n",
    "            target_batch_size = decoder_inputs.shape[0]\n",
    "            if target_batch_size != input_batch_size:\n",
    "                raise ValueError(\"Encoder inputs and Decoder inputs must be equal in their \"\n",
    "                                 \"batch_size, %d != %d\" % (input_batch_size, target_batch_size))\n",
    "            if target_batch_size != decoder_inputs_length.shape[0]:\n",
    "                raise ValueError(\"Decoder targets and their lengths must be equal in their \"\n",
    "                                 \"batch_size, %d != %d\" % (target_batch_size, decoder_inputs_length.shape[0]))\n",
    "\n",
    "        input_feed = {}\n",
    "\n",
    "        input_feed[self.encoder_inputs.name] = encoder_inputs\n",
    "        input_feed[self.encoder_inputs_length.name] = encoder_inputs_length\n",
    "\n",
    "        if not decode:\n",
    "            input_feed[self.decoder_inputs.name] = decoder_inputs\n",
    "            input_feed[self.decoder_inputs_length.name] = decoder_inputs_length\n",
    "\n",
    "        return input_feed\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        self.add_placeholders()\n",
    "        self.build_encoder()\n",
    "        self.build_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "1. Checkpoint path: 모델, summary 저장할 폴더 만들기 \n",
    "2. training(`train-source`), validation(`valid_source`) 데이터 만들기\n",
    "3. 위에서 정의한 코드들 다 불러서 실행시키고 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/15 Batch   20/77 - Loss:  1.931  - Validation loss:  2.000\n",
      "Epoch   1/15 Batch   40/77 - Loss:  1.877  - Validation loss:  1.833\n",
      "Epoch   1/15 Batch   60/77 - Loss:  1.600  - Validation loss:  1.637\n",
      "Epoch   2/15 Batch   20/77 - Loss:  1.400  - Validation loss:  1.459\n",
      "Epoch   2/15 Batch   40/77 - Loss:  1.447  - Validation loss:  1.406\n",
      "Epoch   2/15 Batch   60/77 - Loss:  1.332  - Validation loss:  1.369\n",
      "Epoch   3/15 Batch   20/77 - Loss:  1.253  - Validation loss:  1.304\n",
      "Epoch   3/15 Batch   40/77 - Loss:  1.312  - Validation loss:  1.257\n",
      "Epoch   3/15 Batch   60/77 - Loss:  1.151  - Validation loss:  1.176\n",
      "Epoch   4/15 Batch   20/77 - Loss:  0.929  - Validation loss:  0.971\n",
      "Epoch   4/15 Batch   40/77 - Loss:  0.878  - Validation loss:  1.208\n",
      "Epoch   4/15 Batch   60/77 - Loss:  0.687  - Validation loss:  0.728\n",
      "Epoch   5/15 Batch   20/77 - Loss:  0.286  - Validation loss:  0.340\n",
      "Epoch   5/15 Batch   40/77 - Loss:  0.202  - Validation loss:  0.209\n",
      "Epoch   5/15 Batch   60/77 - Loss:  0.116  - Validation loss:  0.127\n",
      "Epoch   6/15 Batch   20/77 - Loss:  0.041  - Validation loss:  0.056\n",
      "Epoch   6/15 Batch   40/77 - Loss:  0.037  - Validation loss:  0.038\n",
      "Epoch   6/15 Batch   60/77 - Loss:  0.026  - Validation loss:  0.028\n",
      "Epoch   7/15 Batch   20/77 - Loss:  0.014  - Validation loss:  0.018\n",
      "Epoch   7/15 Batch   40/77 - Loss:  0.014  - Validation loss:  0.015\n",
      "Epoch   7/15 Batch   60/77 - Loss:  0.011  - Validation loss:  0.012\n",
      "Epoch   8/15 Batch   20/77 - Loss:  0.164  - Validation loss:  0.157\n",
      "Epoch   8/15 Batch   40/77 - Loss:  0.026  - Validation loss:  0.036\n",
      "Epoch   8/15 Batch   60/77 - Loss:  0.012  - Validation loss:  0.013\n",
      "Epoch   9/15 Batch   20/77 - Loss:  0.007  - Validation loss:  0.008\n",
      "Epoch   9/15 Batch   40/77 - Loss:  0.007  - Validation loss:  0.007\n",
      "Epoch   9/15 Batch   60/77 - Loss:  0.006  - Validation loss:  0.006\n",
      "Epoch  10/15 Batch   20/77 - Loss:  0.004  - Validation loss:  0.005\n",
      "Epoch  10/15 Batch   40/77 - Loss:  0.005  - Validation loss:  0.005\n",
      "Epoch  10/15 Batch   60/77 - Loss:  0.004  - Validation loss:  0.004\n",
      "Epoch  11/15 Batch   20/77 - Loss:  0.003  - Validation loss:  0.004\n",
      "Epoch  11/15 Batch   40/77 - Loss:  0.003  - Validation loss:  0.004\n",
      "Epoch  11/15 Batch   60/77 - Loss:  0.003  - Validation loss:  0.003\n",
      "Epoch  12/15 Batch   20/77 - Loss:  0.002  - Validation loss:  0.003\n",
      "Epoch  12/15 Batch   40/77 - Loss:  0.003  - Validation loss:  0.003\n",
      "Epoch  12/15 Batch   60/77 - Loss:  0.002  - Validation loss:  0.003\n",
      "Epoch  13/15 Batch   20/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  13/15 Batch   40/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  13/15 Batch   60/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  14/15 Batch   20/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  14/15 Batch   40/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  14/15 Batch   60/77 - Loss:  0.002  - Validation loss:  0.002\n",
      "Epoch  15/15 Batch   20/77 - Loss:  0.001  - Validation loss:  0.002\n",
      "Epoch  15/15 Batch   40/77 - Loss:  0.002  - Validation loss:  0.001\n",
      "Epoch  15/15 Batch   60/77 - Loss:  0.001  - Validation loss:  0.001\n",
      "save model checkpoint to ./datasets/runs\\2017-12-23 17-41-03\\checkpoint\\model\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "output_dir = './datasets/runs'\n",
    "\n",
    "# checkpoint path\n",
    "time_now = datetime.datetime.now().strftime('%Y-%m-%d %H-%M-%S')\n",
    "output_dir = os.path.join(output_dir, time_now)\n",
    "checkpoint_dir = os.path.join(output_dir, 'checkpoint')\n",
    "summary_dir = os.path.join(output_dir, 'summaries')\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'model')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    os.makedirs(summary_dir)\n",
    "\n",
    "# config\n",
    "config = Config()\n",
    "\n",
    "train_source = source_letter_ids[config.batch_size:]\n",
    "train_target = [list(reversed(i)) + [3] for i in train_source]\n",
    "valid_source = source_letter_ids[:config.batch_size]\n",
    "valid_target = [list(reversed(i)) + [3] for i in valid_source]\n",
    "(valid_targets_batch, valid_sources_batch, valid_targets_lengths, valid_sources_lengths) = \\\n",
    "    next(get_batches(valid_target, valid_source, config.batch_size, 0, 0))\n",
    "\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "\n",
    "model = Model(config, mode='train')\n",
    "model.build_model()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch_i in range(1, config.epochs+1):\n",
    "    for batch_i, (targets_batch, sources_batch, targets_lengths, sources_lengths) in enumerate(\n",
    "            get_batches(train_target, train_source, config.batch_size, 0, 0)):\n",
    "        train_loss = model.train(sess,\n",
    "                                 sources_batch,\n",
    "                                 sources_lengths,\n",
    "                                 targets_batch,\n",
    "                                 targets_lengths)\n",
    "\n",
    "        if batch_i % display_step == 0 and batch_i > 0:\n",
    "            val_loss = model.eval(sess,\n",
    "                                  valid_sources_batch,\n",
    "                                  valid_sources_lengths,\n",
    "                                  valid_targets_batch,\n",
    "                                  valid_targets_lengths)\n",
    "            print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}  - Validation loss: {:>6.3f}'\n",
    "                  .format(epoch_i, config.epochs, batch_i,\n",
    "                          len(train_source) // config.batch_size, train_loss, val_loss))\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, checkpoint_prefix)\n",
    "print('save model checkpoint to {}'.format(checkpoint_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode\n",
    "\n",
    "- checkpoint를 설정하고 모델을 불러온다. \n",
    "- 예측하고자 하는 데이터를 입력해준다. \n",
    "- 데이터를 숫자로 변경한다. \n",
    "- 모델을 통해 예측한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./datasets/runs/2017-12-21 01-23-49/checkpoint/model\n",
      "model restored from ./datasets/runs/2017-12-21 01-23-49/checkpoint/model\n",
      "hi\n",
      "PREDICTION: ih<EOS>\n",
      "INPUT: hi<PAD><PAD><PAD><PAD><PAD>\n",
      "hello\n",
      "PREDICTION: olleh<EOS>\n",
      "INPUT: hello<PAD><PAD>\n",
      "power\n",
      "PREDICTION: rewop<EOS>\n",
      "INPUT: power<PAD><PAD>\n",
      "fuch\n",
      "PREDICTION: hcuf<EOS>\n",
      "INPUT: fuch<PAD><PAD><PAD>\n",
      "fuck\n",
      "PREDICTION: kcuf<EOS>\n",
      "INPUT: fuck<PAD><PAD><PAD>\n",
      "ssibal\n",
      "PREDICTION: labiss<EOS>\n",
      "INPUT: ssibal<PAD>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "checkpoint_dir = './datasets/runs/2017-12-21 01-23-49/checkpoint/'\n",
    "\n",
    "### sample\n",
    "source_path = './datasets/letters_source.txt'\n",
    "\n",
    "# source -> seq 변환\n",
    "def source_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    sequence_length = 7\n",
    "    return [source_letter_to_int.get(word, source_letter_to_int['<UNK>']) for word in text]\\\n",
    "           + [source_letter_to_int['<PAD>']]*(sequence_length-len(text))\n",
    "    \n",
    "# seq -> source 변환\n",
    "def seq_to_source(seq):\n",
    "    return ''.join([source_int_to_letter[i] for i in seq])\n",
    "\n",
    "config = Config()\n",
    "sess = tf.Session()\n",
    "model = Model(config, mode='inference')\n",
    "model.build_model()\n",
    "\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, checkpoint_file)\n",
    "print('model restored from {}'.format(checkpoint_file))\n",
    "\n",
    "while True:\n",
    "    text_input = input()\n",
    "    text = source_to_seq(text_input)\n",
    "    logits = model.inference_logits\n",
    "    pred = sess.run(logits, feed_dict={model.encoder_inputs: [text]*config.batch_size,\n",
    "                                       model.encoder_inputs_length: [len(text)]*config.batch_size})[1]\n",
    "    print('PREDICTION: {}'.format(seq_to_source(pred)))\n",
    "    print('INPUT: {}'.format(seq_to_source(text)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
