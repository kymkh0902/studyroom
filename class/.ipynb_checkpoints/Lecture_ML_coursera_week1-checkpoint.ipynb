{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning week #1\n",
    "\n",
    "#### 서론\n",
    "\n",
    "초반부에는 전반적인 머신러닝에 대해 현재 어떤 수준에 이르렀는지 소개하고 있다. 이 강의가 만들어진지 3-4년은 더 된 듯하니 \n",
    "지금은 훨씬 더 발전했고 실제로 우리 생활에도 많이 사용되고 있다.\n",
    "\n",
    "아마 초반부에는 Logistic, linear regression 등 기본적이면서 조금은 간단한 모델부터 시작해서 ***필요에 의해서***\n",
    "더 복잡한 모델을 보게 될 것이다.\n",
    "\n",
    "머신러닝 각각의 모델에는 장/단점이 존재해서 *지금 가지고 있는 데이터는 어떤 종류인지, 얼마나 많은지, 고려해야 될 feature가 얼마나 되는지 ... * 등을 고려해서 가장 적합한 모델을 골라야 한다. <br>\n",
    "(물론, 전부다 해보면 좋긴 하겠지만 어차피 시간과의 싸움이라 그러지 않으려고 배운다고 생각하면 되겠다.)\n",
    "\n",
    "물론 지금 가장 뜨거운 딥러닝을 바로 공부하면 좋긴 하겠지만 이 강의를 통해 배우는 내용이 ***머신러닝의 전반적인 내용***이라고 보면 되겠다. <br>\n",
    "**어떤 데이터를 가지고 어떻게 학습시키고 어떤 방식으로 모델을 고르고 어떻게 조건들을 튜닝할 지에 대한 개론** 이라고 봐도 될 듯한데 \n",
    "아마 중간 중간에 조금 어려운 내용이나 그렇게 깊게 공부하지 않아도 될 내용들은(*쓸 일이 없거나 단발적이거나 나중에 배울 내용과 연속성이 없는*) 과감하게 지나가도록 하겠다.\n",
    "\n",
    "이번 강의에서 가장 중요하다고 생각되는 건 아래 두 가지이므로 저 목표들을 달성하도록 노력해보자\n",
    " \n",
    "1) 데이터에 맞는 모델을 설정하고 이를 **end-to-end 학습**시키는 방법을 배운다.  <br>\n",
    " \n",
    "2) 위에 내용을 **프로그래밍으로 구현**해서 직접 결과를 본다.  <br>\n",
    "\n",
    "***\n",
    "#### 강의 내용\n",
    "\n",
    "앞 장에선 주로 학습할 데이터와 답이 함께 존재하는 Supervised Learning에 대해서 계속 배울 것이다. 아마 기억하기론 Unsupervised에 대해서는 거의 가르치지 않았던 것 같다. <br>\n",
    "실제로 우리 주변에서 사용되는 대부분의 모델들이 Supervised로 해결 가능해서 데이터가 있는 어디에서나 사용할 수 있다. (*물론 우리나라 회사에선 안 될거야...*) <br> 근데 아마 추세가 프로그래밍을 잘 모르는 사람도 사용할 수 있도록 플랫폼화 되어서 나올 것이기 때문에 점점 사용하는 사람들이 많아질 것이다. \n",
    "\n",
    "\n",
    "#### Cost function / Gradient Descent\n",
    "\n",
    "머신러닝 거의 대부분의 모델은 **최적화(Optimization)** 시킬 때 Cost function(*loss function이나 objective function과 약간 다르지만 비슷하게 많이 쓰인다.*)을 최소화 하는 방향으로 학습을 시켜준다. \n",
    "\n",
    "방법도 공통적인데 거의 대부분 **Gradient Descent**를 사용한다. 그 이유는 매우 빠르기 때문이다. <br>\n",
    "최소값을 찾는 방법이 여러가지가 있는데 2차 미분의 경우 iteration하는 연산이 필요없이 바로 최소값을 찾을 수 있지만 \n",
    "연산량이 너무 큰 단점이 있어서 거의 항상 Gradient Descent를 사용한다고 보면 된다. \n",
    "\n",
    "***Cost function과 Gradient Descent는 짝꿍이다.*** <br>\n",
    "이게 정말 중요한데 수업 내용을 보면 $\\theta$에 대해서 $J(\\theta)$를 미분한다는 표현이 계속해서 나온다.(derivative of the cost function with respect to $\\theta_j$) <br>\n",
    "\n",
    "즉, 우리가 update하려는 변수($\\theta$)가 cost function 안에 속해있고, gradient를 구해서 update를 하면 우리가 원하는 최적의 변수($\\theta$)를 구할 수 있다는 말이다.\n",
    "\n",
    "그럼 모델을 설계할 때 아래의 단계대로 진행하면 끝이다...(*짱 쉬움...이거 아는데 1년 걸림...*) <br>\n",
    "1. Cost function을 구하고\n",
    "2. 식 내에 있는 parameter들을 본다.\n",
    "3. parameter들에 **대해서** Cost function의 gradient를 구한다.\n",
    "4. 각 parameter들을 update해준다. (Gradient Descent) \n",
    "5. 추가 여러가지 잡다한 것들 고려 등등\n",
    "\n",
    "[단어 내용]\n",
    "1. end-to-end : 데이터 처리부터 학습까지 즉, 처음부터 끝까지에 대한 내용을 내포하는 말\n",
    "2. [Objective function](https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing) : 목적 함수. 우리가 어떤 목적을 갖고 구하려는 함수인데 머신러닝에선 주로 loss function을 의미한다.\n",
    "3. iteration : 반복, for loop가 돌아가는 거라고 생각하며 된다. 주로 학습시킬 때 Cost function의 Gradient를 구하고 update를 하고 \n",
    "또 구하고 update하고....를 엄청나게 많이(몇 천~몇 십만번) 반복한다. \n",
    "4. parameter : 변수를 지칭하는 말. 1강에서 집의 위치, 크기 등을 의미한다고 보면 된다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
