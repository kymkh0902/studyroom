{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 - TensorFLow의 설치 및 기본적인 operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 : Tensor(\"Const_5:0\", shape=(), dtype=float32) node 2: Tensor(\"Const_6:0\", shape=(), dtype=float32)\n",
      "node3 : Tensor(\"Add_2:0\", shape=(), dtype=float32)\n",
      "sess.run(node1, node2): [3.0, 4.0]\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(\"node1 :\", node1, \"node 2:\", node2)\n",
    "print(\"node3 :\", node3)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2):\", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict = {a:3, b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict = {a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 02 - TensorFlow로 간단한 linear regression을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.67382 [ 0.61129528] [-1.58333135]\n",
      "100 0.124133 [ 1.40919745] [-0.93022108]\n",
      "200 0.076707 [ 1.32167208] [-0.7312361]\n",
      "300 0.0474003 [ 1.25286365] [-0.57481837]\n",
      "400 0.0292904 [ 1.19877374] [-0.4518595]\n",
      "500 0.0180997 [ 1.15625429] [-0.35520285]\n",
      "600 0.0111845 [ 1.12283015] [-0.27922174]\n",
      "700 0.00691136 [ 1.09655571] [-0.21949375]\n",
      "800 0.00427082 [ 1.07590163] [-0.1725422]\n",
      "900 0.0026391 [ 1.05966532] [-0.1356338]\n",
      "1000 0.0016308 [ 1.04690254] [-0.10662051]\n",
      "1100 0.00100773 [ 1.03686953] [-0.08381315]\n",
      "1200 0.000622717 [ 1.02898276] [-0.0658848]\n",
      "1300 0.0003848 [ 1.02278316] [-0.0517916]\n",
      "1400 0.000237787 [ 1.01790965] [-0.04071292]\n",
      "1500 0.000146936 [ 1.01407862] [-0.03200395]\n",
      "1600 9.07978e-05 [ 1.01106703] [-0.02515798]\n",
      "1700 5.61061e-05 [ 1.00869954] [-0.0197763]\n",
      "1800 3.46696e-05 [ 1.00683868] [-0.01554601]\n",
      "1900 2.14239e-05 [ 1.00537586] [-0.01222046]\n",
      "2000 1.32391e-05 [ 1.00422597] [-0.00960646]\n"
     ]
    }
   ],
   "source": [
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x_train * w + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost), sess.run(w), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.202881 [ 0.73620844] [ 1.7695502]\n",
      "100 0.0442807 [ 0.86384475] [ 1.59156358]\n",
      "200 0.0224932 [ 0.90295964] [ 1.45034635]\n",
      "300 0.0114257 [ 0.93083769] [ 1.34969783]\n",
      "400 0.00580391 [ 0.95070678] [ 1.27796423]\n",
      "500 0.00294819 [ 0.96486783] [ 1.22683823]\n",
      "600 0.00149759 [ 0.97496057] [ 1.19040012]\n",
      "700 0.000760728 [ 0.98215395] [ 1.16442966]\n",
      "800 0.000386424 [ 0.98728079] [ 1.14592028]\n",
      "900 0.000196288 [ 0.99093491] [ 1.13272786]\n",
      "1000 9.97091e-05 [ 0.99353904] [ 1.12332606]\n",
      "1100 5.06469e-05 [ 0.9953953] [ 1.11662447]\n",
      "1200 2.57278e-05 [ 0.99671811] [ 1.11184859]\n",
      "1300 1.3068e-05 [ 0.99766105] [ 1.10844433]\n",
      "1400 6.63799e-06 [ 0.99833304] [ 1.1060183]\n",
      "1500 3.37104e-06 [ 0.99881196] [ 1.10428905]\n",
      "1600 1.71272e-06 [ 0.99915326] [ 1.10305679]\n",
      "1700 8.69868e-07 [ 0.9993965] [ 1.10217881]\n",
      "1800 4.41982e-07 [ 0.99956989] [ 1.10155284]\n",
      "1900 2.24564e-07 [ 0.99969339] [ 1.10110676]\n",
      "2000 1.1409e-07 [ 0.99978143] [ 1.10078895]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * w + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, w_val, b_val, _ = \\\n",
    "    sess.run([cost, w, b, train], feed_dict = {X : [1, 2, 3, 4, 5], Y : [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost_val, w_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.0995121]\n",
      "[ 3.600389]\n",
      "[ 2.60073996  4.60003853]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - Linear Regression의 cost 최소화의 TensorFlow 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c11f95c7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W : feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.752837 [ 0.59835052]\n",
      "2 0.21414 [ 0.78578699]\n",
      "4 0.0609111 [ 0.88575304]\n",
      "6 0.0173258 [ 0.93906832]\n",
      "8 0.00492821 [ 0.96750313]\n",
      "10 0.00140181 [ 0.98266834]\n",
      "12 0.000398736 [ 0.99075645]\n",
      "14 0.000113417 [ 0.9950701]\n",
      "16 3.22612e-05 [ 0.99737072]\n",
      "18 9.17587e-06 [ 0.99859774]\n",
      "20 2.60995e-06 [ 0.99925214]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * w\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((w * X - Y) * X)\n",
    "descent = w - learning_rate * gradient\n",
    "update = w.assign(descent)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    if step % 2 == 0:\n",
    "        sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "10 1.26667\n",
      "20 1.01778\n",
      "30 1.00119\n",
      "40 1.00008\n",
      "50 1.00001\n",
      "60 1.0\n",
      "70 1.0\n",
      "80 1.0\n",
      "90 1.0\n",
      "100 1.0\n",
      "110 1.0\n",
      "120 1.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(5.0)\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "hypothesis = X * w\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(121):\n",
    "    if step % 10 == 0:\n",
    "        print(step, sess.run(w))\n",
    "        sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04-1 - multi-variable linear regression을 TensorFlow에서 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 45024.5 \n",
      "Prediction :\n",
      " [-41.85175323 -37.90689087 -43.57335663 -49.50513458 -24.12836838]\n",
      "100 cost : 17.5042 \n",
      "Prediction :\n",
      " [ 146.54397583  188.23194885  179.40016174  193.29444885  148.29502869]\n",
      "200 cost : 16.6316 \n",
      "Prediction :\n",
      " [ 146.69772339  188.12605286  179.44667053  193.33258057  148.15228271]\n",
      "300 cost : 15.8049 \n",
      "Prediction :\n",
      " [ 146.84736633  188.02305603  179.49194336  193.36982727  148.01333618]\n",
      "400 cost : 15.0217 \n",
      "Prediction :\n",
      " [ 146.99291992  187.92282104  179.53596497  193.40612793  147.87802124]\n",
      "500 cost : 14.2795 \n",
      "Prediction :\n",
      " [ 147.13453674  187.82527161  179.57879639  193.44154358  147.7462616 ]\n",
      "600 cost : 13.5763 \n",
      "Prediction :\n",
      " [ 147.27230835  187.7303772   179.62042236  193.47613525  147.61798096]\n",
      "700 cost : 12.91 \n",
      "Prediction :\n",
      " [ 147.40637207  187.63803101  179.66093445  193.50987244  147.49305725]\n",
      "800 cost : 12.2786 \n",
      "Prediction :\n",
      " [ 147.53681946  187.54818726  179.70033264  193.5428009   147.37142944]\n",
      "900 cost : 11.6804 \n",
      "Prediction :\n",
      " [ 147.66371155  187.46075439  179.73864746  193.57492065  147.25297546]\n",
      "1000 cost : 11.1135 \n",
      "Prediction :\n",
      " [ 147.78715515  187.37568665  179.77589417  193.60627747  147.13763428]\n",
      "1100 cost : 10.5763 \n",
      "Prediction :\n",
      " [ 147.90722656  187.29292297  179.81211853  193.63687134  147.02529907]\n",
      "1200 cost : 10.0673 \n",
      "Prediction :\n",
      " [ 148.02404785  187.21237183  179.84735107  193.66671753  146.91592407]\n",
      "1300 cost : 9.58492 \n",
      "Prediction :\n",
      " [ 148.13771057  187.13400269  179.88160706  193.69587708  146.80940247]\n",
      "1400 cost : 9.12778 \n",
      "Prediction :\n",
      " [ 148.24829102  187.05775452  179.91491699  193.72433472  146.70567322]\n",
      "1500 cost : 8.69458 \n",
      "Prediction :\n",
      " [ 148.35586548  186.98356628  179.9473114   193.75212097  146.60466003]\n",
      "1600 cost : 8.28408 \n",
      "Prediction :\n",
      " [ 148.46051025  186.91140747  179.9788208   193.7792511   146.50630188]\n",
      "1700 cost : 7.89498 \n",
      "Prediction :\n",
      " [ 148.56231689  186.84115601  180.00944519  193.8057251   146.41049194]\n",
      "1800 cost : 7.52621 \n",
      "Prediction :\n",
      " [ 148.66136169  186.77282715  180.03923035  193.83158875  146.31718445]\n",
      "1900 cost : 7.17679 \n",
      "Prediction :\n",
      " [ 148.75770569  186.70635986  180.06820679  193.85684204  146.22634888]\n",
      "2000 cost : 6.84555 \n",
      "Prediction :\n",
      " [ 148.85140991  186.64169312  180.09635925  193.88150024  146.13783264]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                feed_dict={x1 : x1_data, x2 : x2_data, x3 : x3_data, y : y_data})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"cost :\", cost_val, \"\\nPrediction :\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 14951.8 \n",
      "Prediction :\n",
      " [[ 44.69148254]\n",
      " [ 52.84869766]\n",
      " [ 52.40369797]\n",
      " [ 59.03211594]\n",
      " [ 38.37189102]]\n",
      "100 cost : 6.0354 \n",
      "Prediction :\n",
      " [[ 153.09085083]\n",
      " [ 183.27859497]\n",
      " [ 180.84521484]\n",
      " [ 198.90307617]\n",
      " [ 137.89128113]]\n",
      "200 cost : 5.82031 \n",
      "Prediction :\n",
      " [[ 153.01806641]\n",
      " [ 183.32913208]\n",
      " [ 180.82376099]\n",
      " [ 198.88087463]\n",
      " [ 137.96325684]]\n",
      "300 cost : 5.61609 \n",
      "Prediction :\n",
      " [[ 152.94734192]\n",
      " [ 183.37832642]\n",
      " [ 180.802948  ]\n",
      " [ 198.85916138]\n",
      " [ 138.03343201]]\n",
      "400 cost : 5.42221 \n",
      "Prediction :\n",
      " [[ 152.8785553 ]\n",
      " [ 183.42614746]\n",
      " [ 180.7827301 ]\n",
      " [ 198.83789062]\n",
      " [ 138.10180664]]\n",
      "500 cost : 5.23811 \n",
      "Prediction :\n",
      " [[ 152.81167603]\n",
      " [ 183.47264099]\n",
      " [ 180.76309204]\n",
      " [ 198.81703186]\n",
      " [ 138.16842651]]\n",
      "600 cost : 5.06327 \n",
      "Prediction :\n",
      " [[ 152.74667358]\n",
      " [ 183.5178833 ]\n",
      " [ 180.74401855]\n",
      " [ 198.7966156 ]\n",
      " [ 138.23336792]]\n",
      "700 cost : 4.89719 \n",
      "Prediction :\n",
      " [[ 152.68347168]\n",
      " [ 183.56187439]\n",
      " [ 180.72550964]\n",
      " [ 198.77664185]\n",
      " [ 138.29669189]]\n",
      "800 cost : 4.73944 \n",
      "Prediction :\n",
      " [[ 152.62205505]\n",
      " [ 183.60467529]\n",
      " [ 180.70755005]\n",
      " [ 198.75706482]\n",
      " [ 138.35839844]]\n",
      "900 cost : 4.58955 \n",
      "Prediction :\n",
      " [[ 152.56233215]\n",
      " [ 183.64627075]\n",
      " [ 180.69007874]\n",
      " [ 198.737854  ]\n",
      " [ 138.41853333]]\n",
      "1000 cost : 4.44718 \n",
      "Prediction :\n",
      " [[ 152.50427246]\n",
      " [ 183.68670654]\n",
      " [ 180.67312622]\n",
      " [ 198.71905518]\n",
      " [ 138.47714233]]\n",
      "1100 cost : 4.31181 \n",
      "Prediction :\n",
      " [[ 152.44787598]\n",
      " [ 183.72607422]\n",
      " [ 180.6566925 ]\n",
      " [ 198.70062256]\n",
      " [ 138.53431702]]\n",
      "1200 cost : 4.18322 \n",
      "Prediction :\n",
      " [[ 152.39302063]\n",
      " [ 183.76429749]\n",
      " [ 180.64071655]\n",
      " [ 198.68254089]\n",
      " [ 138.58999634]]\n",
      "1300 cost : 4.06094 \n",
      "Prediction :\n",
      " [[ 152.33970642]\n",
      " [ 183.80149841]\n",
      " [ 180.62521362]\n",
      " [ 198.66482544]\n",
      " [ 138.64430237]]\n",
      "1400 cost : 3.94469 \n",
      "Prediction :\n",
      " [[ 152.28793335]\n",
      " [ 183.83770752]\n",
      " [ 180.61019897]\n",
      " [ 198.64749146]\n",
      " [ 138.69726562]]\n",
      "1500 cost : 3.83414 \n",
      "Prediction :\n",
      " [[ 152.23757935]\n",
      " [ 183.87286377]\n",
      " [ 180.59561157]\n",
      " [ 198.63046265]\n",
      " [ 138.74888611]]\n",
      "1600 cost : 3.72899 \n",
      "Prediction :\n",
      " [[ 152.18862915]\n",
      " [ 183.90705872]\n",
      " [ 180.58143616]\n",
      " [ 198.61373901]\n",
      " [ 138.79919434]]\n",
      "1700 cost : 3.62897 \n",
      "Prediction :\n",
      " [[ 152.14108276]\n",
      " [ 183.94029236]\n",
      " [ 180.56767273]\n",
      " [ 198.59736633]\n",
      " [ 138.8482666 ]]\n",
      "1800 cost : 3.5338 \n",
      "Prediction :\n",
      " [[ 152.09486389]\n",
      " [ 183.97262573]\n",
      " [ 180.55435181]\n",
      " [ 198.58129883]\n",
      " [ 138.89611816]]\n",
      "1900 cost : 3.44321 \n",
      "Prediction :\n",
      " [[ 152.04998779]\n",
      " [ 184.00405884]\n",
      " [ 180.54144287]\n",
      " [ 198.56552124]\n",
      " [ 138.94277954]]\n",
      "2000 cost : 3.35702 \n",
      "Prediction :\n",
      " [[ 152.00636292]\n",
      " [ 184.03462219]\n",
      " [ 180.52888489]\n",
      " [ 198.55006409]\n",
      " [ 138.98826599]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]\n",
    "y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(x, w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x : x_data, y : y_data})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"cost :\", cost_val, \"\\nPrediction :\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04-2 - TensorFlow로 파일에서 데이타 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) \n",
      " [[  73.   80.   75.]\n",
      " [  93.   88.   93.]\n",
      " [  89.   91.   90.]\n",
      " [  96.   98.  100.]\n",
      " [  73.   66.   70.]\n",
      " [  53.   46.   55.]\n",
      " [  69.   74.   77.]\n",
      " [  47.   56.   60.]\n",
      " [  87.   79.   90.]\n",
      " [  79.   70.   88.]\n",
      " [  69.   70.   73.]\n",
      " [  70.   65.   74.]\n",
      " [  93.   95.   91.]\n",
      " [  79.   80.   73.]\n",
      " [  70.   73.   78.]\n",
      " [  93.   89.   96.]\n",
      " [  78.   75.   68.]\n",
      " [  81.   90.   93.]\n",
      " [  88.   92.   86.]\n",
      " [  78.   83.   77.]\n",
      " [  82.   86.   90.]\n",
      " [  86.   82.   89.]\n",
      " [  78.   83.   85.]\n",
      " [  76.   83.   71.]\n",
      " [  96.   93.   95.]] \n",
      " 25\n",
      "(25, 1) \n",
      " [[ 152.]\n",
      " [ 185.]\n",
      " [ 180.]\n",
      " [ 196.]\n",
      " [ 142.]\n",
      " [ 101.]\n",
      " [ 149.]\n",
      " [ 115.]\n",
      " [ 175.]\n",
      " [ 164.]\n",
      " [ 141.]\n",
      " [ 141.]\n",
      " [ 184.]\n",
      " [ 152.]\n",
      " [ 148.]\n",
      " [ 192.]\n",
      " [ 147.]\n",
      " [ 183.]\n",
      " [ 177.]\n",
      " [ 159.]\n",
      " [ 177.]\n",
      " [ 175.]\n",
      " [ 175.]\n",
      " [ 149.]\n",
      " [ 192.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, \"\\n\", x_data, \"\\n\", len(x_data))\n",
    "print(y_data.shape, \"\\n\", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 2289.26 \n",
      "Prediction :\n",
      " [[ 104.61631775]\n",
      " [ 135.23020935]\n",
      " [ 128.41471863]\n",
      " [ 139.91183472]\n",
      " [ 105.3000946 ]\n",
      " [  78.54219055]\n",
      " [ 101.92706299]\n",
      " [  71.43245697]\n",
      " [ 128.50344849]\n",
      " [ 119.80467224]\n",
      " [ 100.96833801]\n",
      " [ 103.67321777]\n",
      " [ 132.8686676 ]\n",
      " [ 110.98118591]\n",
      " [ 103.79542542]\n",
      " [ 136.36750793]\n",
      " [ 108.57236481]\n",
      " [ 120.28695679]\n",
      " [ 125.19992065]\n",
      " [ 110.93862915]\n",
      " [ 120.98745728]\n",
      " [ 126.21684265]\n",
      " [ 114.52912903]\n",
      " [ 105.82492065]\n",
      " [ 138.71342468]]\n",
      "100 cost : 25.4015 \n",
      "Prediction :\n",
      " [[ 149.42985535]\n",
      " [ 188.8820343 ]\n",
      " [ 181.38418579]\n",
      " [ 197.63291931]\n",
      " [ 146.13867188]\n",
      " [ 108.67776489]\n",
      " [ 145.24186707]\n",
      " [ 103.70137024]\n",
      " [ 178.63697815]\n",
      " [ 166.29547119]\n",
      " [ 142.60307312]\n",
      " [ 144.64610291]\n",
      " [ 187.55534363]\n",
      " [ 156.37968445]\n",
      " [ 147.28166199]\n",
      " [ 190.86276245]\n",
      " [ 151.70271301]\n",
      " [ 172.33874512]\n",
      " [ 177.362854  ]\n",
      " [ 157.64082336]\n",
      " [ 171.73892212]\n",
      " [ 176.59555054]\n",
      " [ 162.9249115 ]\n",
      " [ 150.92080688]\n",
      " [ 194.33442688]]\n",
      "200 cost : 24.4555 \n",
      "Prediction :\n",
      " [[ 149.51425171]\n",
      " [ 188.77856445]\n",
      " [ 181.38514709]\n",
      " [ 197.66648865]\n",
      " [ 145.98199463]\n",
      " [ 108.58855438]\n",
      " [ 145.37295532]\n",
      " [ 103.95271301]\n",
      " [ 178.53251648]\n",
      " [ 166.25236511]\n",
      " [ 142.63482666]\n",
      " [ 144.59951782]\n",
      " [ 187.51913452]\n",
      " [ 156.28892517]\n",
      " [ 147.38635254]\n",
      " [ 190.80780029]\n",
      " [ 151.51306152]\n",
      " [ 172.56417847]\n",
      " [ 177.35469055]\n",
      " [ 157.66165161]\n",
      " [ 171.85162354]\n",
      " [ 176.54348755]\n",
      " [ 163.04043579]\n",
      " [ 150.9210968 ]\n",
      " [ 194.24385071]]\n",
      "300 cost : 23.5556 \n",
      "Prediction :\n",
      " [[ 149.59657288]\n",
      " [ 188.6776123 ]\n",
      " [ 181.38609314]\n",
      " [ 197.69921875]\n",
      " [ 145.82914734]\n",
      " [ 108.50147247]\n",
      " [ 145.5007782 ]\n",
      " [ 104.19781494]\n",
      " [ 178.43057251]\n",
      " [ 166.21020508]\n",
      " [ 142.665802  ]\n",
      " [ 144.55400085]\n",
      " [ 187.4838562 ]\n",
      " [ 156.20046997]\n",
      " [ 147.48840332]\n",
      " [ 190.75415039]\n",
      " [ 151.32815552]\n",
      " [ 172.78399658]\n",
      " [ 177.3467865 ]\n",
      " [ 157.68199158]\n",
      " [ 171.96151733]\n",
      " [ 176.49264526]\n",
      " [ 163.15307617]\n",
      " [ 150.92144775]\n",
      " [ 194.15551758]]\n",
      "400 cost : 22.6996 \n",
      "Prediction :\n",
      " [[ 149.67694092]\n",
      " [ 188.57914734]\n",
      " [ 181.38703918]\n",
      " [ 197.7311554 ]\n",
      " [ 145.68006897]\n",
      " [ 108.41649628]\n",
      " [ 145.62542725]\n",
      " [ 104.4368515 ]\n",
      " [ 178.33108521]\n",
      " [ 166.16896057]\n",
      " [ 142.69598389]\n",
      " [ 144.50956726]\n",
      " [ 187.44949341]\n",
      " [ 156.11427307]\n",
      " [ 147.58792114]\n",
      " [ 190.70178223]\n",
      " [ 151.14787292]\n",
      " [ 172.99841309]\n",
      " [ 177.33914185]\n",
      " [ 157.70188904]\n",
      " [ 172.06869507]\n",
      " [ 176.44303894]\n",
      " [ 163.26293945]\n",
      " [ 150.92190552]\n",
      " [ 194.0693512 ]]\n",
      "500 cost : 21.8853 \n",
      "Prediction :\n",
      " [[ 149.75535583]\n",
      " [ 188.483078  ]\n",
      " [ 181.38798523]\n",
      " [ 197.76231384]\n",
      " [ 145.53465271]\n",
      " [ 108.33357239]\n",
      " [ 145.74699402]\n",
      " [ 104.66997528]\n",
      " [ 178.23399353]\n",
      " [ 166.12863159]\n",
      " [ 142.72541809]\n",
      " [ 144.46617126]\n",
      " [ 187.41600037]\n",
      " [ 156.03024292]\n",
      " [ 147.68496704]\n",
      " [ 190.65066528]\n",
      " [ 150.97209167]\n",
      " [ 173.20750427]\n",
      " [ 177.33172607]\n",
      " [ 157.72135925]\n",
      " [ 172.17320251]\n",
      " [ 176.3946228 ]\n",
      " [ 163.37010193]\n",
      " [ 150.92242432]\n",
      " [ 193.9853363 ]]\n",
      "600 cost : 21.1107 \n",
      "Prediction :\n",
      " [[ 149.8318634 ]\n",
      " [ 188.38937378]\n",
      " [ 181.38893127]\n",
      " [ 197.79269409]\n",
      " [ 145.39280701]\n",
      " [ 108.25263214]\n",
      " [ 145.86557007]\n",
      " [ 104.89732361]\n",
      " [ 178.13923645]\n",
      " [ 166.08921814]\n",
      " [ 142.75411987]\n",
      " [ 144.42381287]\n",
      " [ 187.38340759]\n",
      " [ 155.948349  ]\n",
      " [ 147.77960205]\n",
      " [ 190.6007843 ]\n",
      " [ 150.80070496]\n",
      " [ 173.41145325]\n",
      " [ 177.32455444]\n",
      " [ 157.74038696]\n",
      " [ 172.27513123]\n",
      " [ 176.34738159]\n",
      " [ 163.47462463]\n",
      " [ 150.92303467]\n",
      " [ 193.90336609]]\n",
      "700 cost : 20.3738 \n",
      "Prediction :\n",
      " [[ 149.90652466]\n",
      " [ 188.29794312]\n",
      " [ 181.38986206]\n",
      " [ 197.8223114 ]\n",
      " [ 145.25444031]\n",
      " [ 108.17364502]\n",
      " [ 145.98118591]\n",
      " [ 105.11903381]\n",
      " [ 178.04676819]\n",
      " [ 166.05064392]\n",
      " [ 142.78208923]\n",
      " [ 144.38244629]\n",
      " [ 187.35162354]\n",
      " [ 155.86853027]\n",
      " [ 147.87185669]\n",
      " [ 190.55212402]\n",
      " [ 150.6335907 ]\n",
      " [ 173.61035156]\n",
      " [ 177.31759644]\n",
      " [ 157.75898743]\n",
      " [ 172.37451172]\n",
      " [ 176.30123901]\n",
      " [ 163.57653809]\n",
      " [ 150.9236908 ]\n",
      " [ 193.82344055]]\n",
      "800 cost : 19.6729 \n",
      "Prediction :\n",
      " [[ 149.97940063]\n",
      " [ 188.20878601]\n",
      " [ 181.39079285]\n",
      " [ 197.85121155]\n",
      " [ 145.11949158]\n",
      " [ 108.09656525]\n",
      " [ 146.09394836]\n",
      " [ 105.33526611]\n",
      " [ 177.95652771]\n",
      " [ 166.01295471]\n",
      " [ 142.80937195]\n",
      " [ 144.34207153]\n",
      " [ 187.32069397]\n",
      " [ 155.79074097]\n",
      " [ 147.96183777]\n",
      " [ 190.50462341]\n",
      " [ 150.47067261]\n",
      " [ 173.80433655]\n",
      " [ 177.31086731]\n",
      " [ 157.7771759 ]\n",
      " [ 172.47145081]\n",
      " [ 176.25624084]\n",
      " [ 163.6759491 ]\n",
      " [ 150.92442322]\n",
      " [ 193.7454834 ]]\n",
      "900 cost : 19.0062 \n",
      "Prediction :\n",
      " [[ 150.05050659]\n",
      " [ 188.12179565]\n",
      " [ 181.39172363]\n",
      " [ 197.87939453]\n",
      " [ 144.987854  ]\n",
      " [ 108.02132416]\n",
      " [ 146.20391846]\n",
      " [ 105.54611969]\n",
      " [ 177.86846924]\n",
      " [ 165.97608948]\n",
      " [ 142.83596802]\n",
      " [ 144.30262756]\n",
      " [ 187.29052734]\n",
      " [ 155.71492004]\n",
      " [ 148.04957581]\n",
      " [ 190.45828247]\n",
      " [ 150.31181335]\n",
      " [ 173.99351501]\n",
      " [ 177.30435181]\n",
      " [ 157.79496765]\n",
      " [ 172.56594849]\n",
      " [ 176.21231079]\n",
      " [ 163.77290344]\n",
      " [ 150.92521667]\n",
      " [ 193.66944885]]\n",
      "1000 cost : 18.372 \n",
      "Prediction :\n",
      " [[ 150.11990356]\n",
      " [ 188.03695679]\n",
      " [ 181.39263916]\n",
      " [ 197.90689087]\n",
      " [ 144.85946655]\n",
      " [ 107.94792938]\n",
      " [ 146.31118774]\n",
      " [ 105.75177002]\n",
      " [ 177.782547  ]\n",
      " [ 165.94006348]\n",
      " [ 142.86190796]\n",
      " [ 144.2641449 ]\n",
      " [ 187.26116943]\n",
      " [ 155.64099121]\n",
      " [ 148.13513184]\n",
      " [ 190.41305542]\n",
      " [ 150.15693665]\n",
      " [ 174.17803955]\n",
      " [ 177.29803467]\n",
      " [ 157.81237793]\n",
      " [ 172.65814209]\n",
      " [ 176.16946411]\n",
      " [ 163.86749268]\n",
      " [ 150.92607117]\n",
      " [ 193.5953064 ]]\n",
      "1100 cost : 17.7687 \n",
      "Prediction :\n",
      " [[ 150.18760681]\n",
      " [ 187.95417786]\n",
      " [ 181.39356995]\n",
      " [ 197.93373108]\n",
      " [ 144.73420715]\n",
      " [ 107.87628937]\n",
      " [ 146.41578674]\n",
      " [ 105.95232391]\n",
      " [ 177.69869995]\n",
      " [ 165.90483093]\n",
      " [ 142.88720703]\n",
      " [ 144.2265625 ]\n",
      " [ 187.2325592 ]\n",
      " [ 155.56896973]\n",
      " [ 148.21855164]\n",
      " [ 190.36891174]\n",
      " [ 150.00592041]\n",
      " [ 174.35798645]\n",
      " [ 177.29191589]\n",
      " [ 157.82937622]\n",
      " [ 172.74803162]\n",
      " [ 176.12763977]\n",
      " [ 163.95973206]\n",
      " [ 150.92697144]\n",
      " [ 193.522995  ]]\n",
      "1200 cost : 17.1948 \n",
      "Prediction :\n",
      " [[ 150.25367737]\n",
      " [ 187.8734436 ]\n",
      " [ 181.39447021]\n",
      " [ 197.95988464]\n",
      " [ 144.61206055]\n",
      " [ 107.80638123]\n",
      " [ 146.51779175]\n",
      " [ 106.1479187 ]\n",
      " [ 177.61686707]\n",
      " [ 165.8704071 ]\n",
      " [ 142.91186523]\n",
      " [ 144.18986511]\n",
      " [ 187.2046814 ]\n",
      " [ 155.49874878]\n",
      " [ 148.29989624]\n",
      " [ 190.32585144]\n",
      " [ 149.8586731 ]\n",
      " [ 174.53349304]\n",
      " [ 177.28599548]\n",
      " [ 157.84599304]\n",
      " [ 172.8356781 ]\n",
      " [ 176.08680725]\n",
      " [ 164.04966736]\n",
      " [ 150.92790222]\n",
      " [ 193.45246887]]\n",
      "1300 cost : 16.6489 \n",
      "Prediction :\n",
      " [[ 150.31813049]\n",
      " [ 187.79467773]\n",
      " [ 181.39537048]\n",
      " [ 197.98539734]\n",
      " [ 144.4928894 ]\n",
      " [ 107.73816681]\n",
      " [ 146.61726379]\n",
      " [ 106.33866119]\n",
      " [ 177.53700256]\n",
      " [ 165.83674622]\n",
      " [ 142.93589783]\n",
      " [ 144.15405273]\n",
      " [ 187.17752075]\n",
      " [ 155.43031311]\n",
      " [ 148.37919617]\n",
      " [ 190.28379822]\n",
      " [ 149.71510315]\n",
      " [ 174.70466614]\n",
      " [ 177.28022766]\n",
      " [ 157.86222839]\n",
      " [ 172.9211731 ]\n",
      " [ 176.04696655]\n",
      " [ 164.13739014]\n",
      " [ 150.92887878]\n",
      " [ 193.38368225]]\n",
      "1400 cost : 16.1296 \n",
      "Prediction :\n",
      " [[ 150.38104248]\n",
      " [ 187.71784973]\n",
      " [ 181.39625549]\n",
      " [ 198.01029968]\n",
      " [ 144.37666321]\n",
      " [ 107.67159271]\n",
      " [ 146.71429443]\n",
      " [ 106.52468109]\n",
      " [ 177.45909119]\n",
      " [ 165.80384827]\n",
      " [ 142.95935059]\n",
      " [ 144.11907959]\n",
      " [ 187.15107727]\n",
      " [ 155.36360168]\n",
      " [ 148.45655823]\n",
      " [ 190.24281311]\n",
      " [ 149.57511902]\n",
      " [ 174.87159729]\n",
      " [ 177.27467346]\n",
      " [ 157.87812805]\n",
      " [ 173.00456238]\n",
      " [ 176.00810242]\n",
      " [ 164.22296143]\n",
      " [ 150.92990112]\n",
      " [ 193.31660461]]\n",
      "1500 cost : 15.6356 \n",
      "Prediction :\n",
      " [[ 150.44242859]\n",
      " [ 187.64291382]\n",
      " [ 181.39715576]\n",
      " [ 198.03457642]\n",
      " [ 144.26330566]\n",
      " [ 107.60663605]\n",
      " [ 146.80889893]\n",
      " [ 106.70610809]\n",
      " [ 177.38305664]\n",
      " [ 165.771698  ]\n",
      " [ 142.98219299]\n",
      " [ 144.08494568]\n",
      " [ 187.12528992]\n",
      " [ 155.29856873]\n",
      " [ 148.53198242]\n",
      " [ 190.20278931]\n",
      " [ 149.43862915]\n",
      " [ 175.03440857]\n",
      " [ 177.26928711]\n",
      " [ 157.89364624]\n",
      " [ 173.08584595]\n",
      " [ 175.97015381]\n",
      " [ 164.306427  ]\n",
      " [ 150.93095398]\n",
      " [ 193.25119019]]\n",
      "1600 cost : 15.1657 \n",
      "Prediction :\n",
      " [[ 150.50231934]\n",
      " [ 187.56982422]\n",
      " [ 181.39801025]\n",
      " [ 198.05822754]\n",
      " [ 144.15272522]\n",
      " [ 107.54324341]\n",
      " [ 146.90118408]\n",
      " [ 106.88302612]\n",
      " [ 177.30886841]\n",
      " [ 165.74026489]\n",
      " [ 143.00448608]\n",
      " [ 144.05162048]\n",
      " [ 187.10017395]\n",
      " [ 155.23516846]\n",
      " [ 148.60552979]\n",
      " [ 190.16372681]\n",
      " [ 149.30552673]\n",
      " [ 175.19320679]\n",
      " [ 177.2640686 ]\n",
      " [ 157.90881348]\n",
      " [ 173.16513062]\n",
      " [ 175.93313599]\n",
      " [ 164.38778687]\n",
      " [ 150.93203735]\n",
      " [ 193.18736267]]\n",
      "1700 cost : 14.7187 \n",
      "Prediction :\n",
      " [[ 150.5607605 ]\n",
      " [ 187.49850464]\n",
      " [ 181.39888   ]\n",
      " [ 198.0813446 ]\n",
      " [ 144.0448761 ]\n",
      " [ 107.48138428]\n",
      " [ 146.99119568]\n",
      " [ 107.05556488]\n",
      " [ 177.23648071]\n",
      " [ 165.70956421]\n",
      " [ 143.02622986]\n",
      " [ 144.01908875]\n",
      " [ 187.07569885]\n",
      " [ 155.17338562]\n",
      " [ 148.67724609]\n",
      " [ 190.12562561]\n",
      " [ 149.17576599]\n",
      " [ 175.34806824]\n",
      " [ 177.25898743]\n",
      " [ 157.92362976]\n",
      " [ 173.24246216]\n",
      " [ 175.89701843]\n",
      " [ 164.46717834]\n",
      " [ 150.93313599]\n",
      " [ 193.12513733]]\n",
      "1800 cost : 14.2935 \n",
      "Prediction :\n",
      " [[ 150.61776733]\n",
      " [ 187.42892456]\n",
      " [ 181.3997345 ]\n",
      " [ 198.10385132]\n",
      " [ 143.93966675]\n",
      " [ 107.42102814]\n",
      " [ 147.07893372]\n",
      " [ 107.22383881]\n",
      " [ 177.16583252]\n",
      " [ 165.67953491]\n",
      " [ 143.0473938 ]\n",
      " [ 143.98733521]\n",
      " [ 187.05183411]\n",
      " [ 155.11314392]\n",
      " [ 148.74716187]\n",
      " [ 190.08843994]\n",
      " [ 149.04920959]\n",
      " [ 175.49908447]\n",
      " [ 177.25405884]\n",
      " [ 157.93811035]\n",
      " [ 173.31785583]\n",
      " [ 175.86174011]\n",
      " [ 164.54458618]\n",
      " [ 150.93424988]\n",
      " [ 193.06442261]]\n",
      "1900 cost : 13.8891 \n",
      "Prediction :\n",
      " [[ 150.67341614]\n",
      " [ 187.36109924]\n",
      " [ 181.40058899]\n",
      " [ 198.12583923]\n",
      " [ 143.83705139]\n",
      " [ 107.36213684]\n",
      " [ 147.16453552]\n",
      " [ 107.38794708]\n",
      " [ 177.09690857]\n",
      " [ 165.65022278]\n",
      " [ 143.06806946]\n",
      " [ 143.9563446 ]\n",
      " [ 187.02861023]\n",
      " [ 155.05444336]\n",
      " [ 148.81538391]\n",
      " [ 190.0521698 ]\n",
      " [ 148.92584229]\n",
      " [ 175.64640808]\n",
      " [ 177.24931335]\n",
      " [ 157.95227051]\n",
      " [ 173.3914032 ]\n",
      " [ 175.82736206]\n",
      " [ 164.62010193]\n",
      " [ 150.93540955]\n",
      " [ 193.00523376]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 cost : 13.5043 \n",
      "Prediction :\n",
      " [[ 150.72769165]\n",
      " [ 187.29490662]\n",
      " [ 181.40142822]\n",
      " [ 198.14727783]\n",
      " [ 143.73696899]\n",
      " [ 107.30465698]\n",
      " [ 147.24801636]\n",
      " [ 107.54798889]\n",
      " [ 177.02966309]\n",
      " [ 165.62155151]\n",
      " [ 143.08821106]\n",
      " [ 143.92608643]\n",
      " [ 187.00598145]\n",
      " [ 154.99719238]\n",
      " [ 148.88186646]\n",
      " [ 190.01676941]\n",
      " [ 148.80554199]\n",
      " [ 175.79006958]\n",
      " [ 177.24468994]\n",
      " [ 157.96611023]\n",
      " [ 173.46313477]\n",
      " [ 175.79379272]\n",
      " [ 164.6937561 ]\n",
      " [ 150.93656921]\n",
      " [ 192.94750977]]\n",
      "Your score will be  [[ 197.3812561]]\n",
      "Other score will be  [[ 165.28079224]\n",
      " [ 175.77459717]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(x, w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x : x_data, y : y_data})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"cost :\", cost_val, \"\\nPrediction :\\n\", hy_val)\n",
    "        \n",
    "print(\"Your score will be \", sess.run(hypothesis, feed_dict={x : [[100, 70, 101]]}))\n",
    "print(\"Other score will be \", sess.run(hypothesis, feed_dict={x : [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 315.673 \n",
      "Prediction :\n",
      " [[ 177.12754822]\n",
      " [ 205.06286621]\n",
      " [ 206.24278259]\n",
      " [ 222.1517334 ]\n",
      " [ 156.57972717]\n",
      " [ 110.9234314 ]\n",
      " [ 164.97575378]\n",
      " [ 120.65338898]\n",
      " [ 186.92457581]\n",
      " [ 167.12945557]]\n",
      "100 cost : 43.715 \n",
      "Prediction :\n",
      " [[ 158.49514771]\n",
      " [ 183.09281921]\n",
      " [ 184.36381531]\n",
      " [ 198.48007202]\n",
      " [ 139.80056763]\n",
      " [  98.84344482]\n",
      " [ 147.36991882]\n",
      " [ 107.74720764]\n",
      " [ 166.68127441]\n",
      " [ 148.76246643]]\n",
      "200 cost : 39.9688 \n",
      "Prediction :\n",
      " [[ 158.24972534]\n",
      " [ 183.20530701]\n",
      " [ 184.25236511]\n",
      " [ 198.50881958]\n",
      " [ 139.86375427]\n",
      " [  99.16927338]\n",
      " [ 147.50035095]\n",
      " [ 107.98412323]\n",
      " [ 167.06434631]\n",
      " [ 149.48551941]]\n",
      "300 cost : 36.5665 \n",
      "Prediction :\n",
      " [[ 158.01580811]\n",
      " [ 183.31208801]\n",
      " [ 184.14585876]\n",
      " [ 198.53642273]\n",
      " [ 139.92311096]\n",
      " [  99.47994995]\n",
      " [ 147.62574768]\n",
      " [ 108.21202087]\n",
      " [ 167.42958069]\n",
      " [ 150.1759491 ]]\n",
      "400 cost : 33.4774 \n",
      "Prediction :\n",
      " [[ 157.79283142]\n",
      " [ 183.41339111]\n",
      " [ 184.04411316]\n",
      " [ 198.56298828]\n",
      " [ 139.97880554]\n",
      " [  99.77614594]\n",
      " [ 147.74632263]\n",
      " [ 108.43125153]\n",
      " [ 167.77780151]\n",
      " [ 150.83518982]]\n",
      "500 cost : 30.673 \n",
      "Prediction :\n",
      " [[ 157.58033752]\n",
      " [ 183.50953674]\n",
      " [ 183.94691467]\n",
      " [ 198.58856201]\n",
      " [ 140.03105164]\n",
      " [ 100.05853271]\n",
      " [ 147.86227417]\n",
      " [ 108.6421814 ]\n",
      " [ 168.10978699]\n",
      " [ 151.46466064]]\n",
      "600 cost : 28.1276 \n",
      "Prediction :\n",
      " [[ 157.37785339]\n",
      " [ 183.60075378]\n",
      " [ 183.85403442]\n",
      " [ 198.61314392]\n",
      " [ 140.08001709]\n",
      " [ 100.32775879]\n",
      " [ 147.97380066]\n",
      " [ 108.84514618]\n",
      " [ 168.42628479]\n",
      " [ 152.06570435]]\n",
      "700 cost : 25.8179 \n",
      "Prediction :\n",
      " [[ 157.18486023]\n",
      " [ 183.68725586]\n",
      " [ 183.76528931]\n",
      " [ 198.63679504]\n",
      " [ 140.12585449]\n",
      " [ 100.58439636]\n",
      " [ 148.08106995]\n",
      " [ 109.04043579]\n",
      " [ 168.72801208]\n",
      " [ 152.63957214]]\n",
      "800 cost : 23.7226 \n",
      "Prediction :\n",
      " [[ 157.00093079]\n",
      " [ 183.76927185]\n",
      " [ 183.68049622]\n",
      " [ 198.65957642]\n",
      " [ 140.16876221]\n",
      " [ 100.82904053]\n",
      " [ 148.18424988]\n",
      " [ 109.22839355]\n",
      " [ 169.01560974]\n",
      " [ 153.1875    ]]\n",
      "900 cost : 21.8222 \n",
      "Prediction :\n",
      " [[ 156.82571411]\n",
      " [ 183.84709167]\n",
      " [ 183.59950256]\n",
      " [ 198.68151855]\n",
      " [ 140.20889282]\n",
      " [ 101.06224823]\n",
      " [ 148.28352356]\n",
      " [ 109.40930939]\n",
      " [ 169.2897644 ]\n",
      " [ 153.7106781 ]]\n",
      "1000 cost : 20.099 \n",
      "Prediction :\n",
      " [[ 156.6587677 ]\n",
      " [ 183.92082214]\n",
      " [ 183.52210999]\n",
      " [ 198.70259094]\n",
      " [ 140.24635315]\n",
      " [ 101.28450775]\n",
      " [ 148.37901306]\n",
      " [ 109.58342743]\n",
      " [ 169.55108643]\n",
      " [ 154.21018982]]\n",
      "1100 cost : 18.537 \n",
      "Prediction :\n",
      " [[ 156.49971008]\n",
      " [ 183.99069214]\n",
      " [ 183.44815063]\n",
      " [ 198.72288513]\n",
      " [ 140.28131104]\n",
      " [ 101.49635315]\n",
      " [ 148.47091675]\n",
      " [ 109.75106049]\n",
      " [ 169.80014038]\n",
      " [ 154.68710327]]\n",
      "1200 cost : 17.1215 \n",
      "Prediction :\n",
      " [[ 156.34814453]\n",
      " [ 184.05688477]\n",
      " [ 183.37748718]\n",
      " [ 198.74241638]\n",
      " [ 140.31387329]\n",
      " [ 101.69825745]\n",
      " [ 148.55932617]\n",
      " [ 109.91246033]\n",
      " [ 170.03749084]\n",
      " [ 155.14242554]]\n",
      "1300 cost : 15.8391 \n",
      "Prediction :\n",
      " [[ 156.20379639]\n",
      " [ 184.11959839]\n",
      " [ 183.30999756]\n",
      " [ 198.76123047]\n",
      " [ 140.34420776]\n",
      " [ 101.89067078]\n",
      " [ 148.6444397 ]\n",
      " [ 110.06786346]\n",
      " [ 170.26370239]\n",
      " [ 155.57717896]]\n",
      "1400 cost : 14.6778 \n",
      "Prediction :\n",
      " [[ 156.06628418]\n",
      " [ 184.17897034]\n",
      " [ 183.24549866]\n",
      " [ 198.77934265]\n",
      " [ 140.37242126]\n",
      " [ 102.07402802]\n",
      " [ 148.72634888]\n",
      " [ 110.21749878]\n",
      " [ 170.47926331]\n",
      " [ 155.99223328]]\n",
      "1500 cost : 13.6264 \n",
      "Prediction :\n",
      " [[ 155.93530273]\n",
      " [ 184.23519897]\n",
      " [ 183.18385315]\n",
      " [ 198.79678345]\n",
      " [ 140.39859009]\n",
      " [ 102.24874115]\n",
      " [ 148.80519104]\n",
      " [ 110.36161804]\n",
      " [ 170.68466187]\n",
      " [ 156.38848877]]\n",
      "1600 cost : 12.6749 \n",
      "Prediction :\n",
      " [[ 155.81056213]\n",
      " [ 184.28839111]\n",
      " [ 183.12496948]\n",
      " [ 198.81356812]\n",
      " [ 140.42286682]\n",
      " [ 102.41521454]\n",
      " [ 148.88108826]\n",
      " [ 110.50041199]\n",
      " [ 170.88038635]\n",
      " [ 156.76679993]]\n",
      "1700 cost : 11.8142 \n",
      "Prediction :\n",
      " [[ 155.69177246]\n",
      " [ 184.33877563]\n",
      " [ 183.06871033]\n",
      " [ 198.82977295]\n",
      " [ 140.44535828]\n",
      " [ 102.57383728]\n",
      " [ 148.95417786]\n",
      " [ 110.63412476]\n",
      " [ 171.06686401]\n",
      " [ 157.12797546]]\n",
      "1800 cost : 11.0359 \n",
      "Prediction :\n",
      " [[ 155.5786438 ]\n",
      " [ 184.38639832]\n",
      " [ 183.01495361]\n",
      " [ 198.84533691]\n",
      " [ 140.46612549]\n",
      " [ 102.72493744]\n",
      " [ 149.02453613]\n",
      " [ 110.76291656]\n",
      " [ 171.24452209]\n",
      " [ 157.47279358]]\n",
      "1900 cost : 10.3324 \n",
      "Prediction :\n",
      " [[ 155.47091675]\n",
      " [ 184.431427  ]\n",
      " [ 182.96357727]\n",
      " [ 198.86035156]\n",
      " [ 140.48529053]\n",
      " [ 102.86889648]\n",
      " [ 149.09228516]\n",
      " [ 110.88702393]\n",
      " [ 171.41375732]\n",
      " [ 157.80195618]]\n",
      "2000 cost : 9.69686 \n",
      "Prediction :\n",
      " [[ 155.36834717]\n",
      " [ 184.47401428]\n",
      " [ 182.91452026]\n",
      " [ 198.87481689]\n",
      " [ 140.50292969]\n",
      " [ 103.00602722]\n",
      " [ 149.15753174]\n",
      " [ 111.0065918 ]\n",
      " [ 171.57498169]\n",
      " [ 158.11621094]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data-01-test-score.csv'], shuffle=False, name = 'filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "    \n",
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(x, w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess = sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={x : x_batch, y : y_batch})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"cost :\", cost_val, \"\\nPrediction :\\n\", hy_val)\n",
    "        \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
